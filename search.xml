<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Macbook pro 2015升级硬盘+开机黑屏故障处理]]></title>
    <url>%2F2020%2F05%2F25%2FMacbook-pro-2015%E5%8D%87%E7%BA%A7%E7%A1%AC%E7%9B%98-%E5%BC%80%E6%9C%BA%E9%BB%91%E5%B1%8F%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[最近买了一台二手的丐版macbook pro 2015款 13寸，很是好用。美中不足的是硬盘只有128G，故研究了一下升级ssd的过程。升级过程比较简单，此文主要说的是一些升级过程中遇到的问题以及解决方法。一. 升级过程问题： 升级硬盘安装过程非常简单，网上已有大量的博文介绍，在此不在多写。我使用的是经过大量网友验证的 Intel 760p，确实很稳； 拆机过程中，强烈建议将电池连接断开，防止因带电操作，造成硬件损坏。电池是用一个卡扣连在主板上的，稍微向上用点力就可以扣下来。此处盗用一个图： 特别需要注意的是MacOS仅在10.13版本，也就是 High Sierra 才开始原生支持nvme驱动。这个版本之前的MacOS版本都是不支持nvme驱动的。故建议在安装系最低也要安装到10.13，建议安装 10.14（Mojave） 版本； 在装好ssd，重新恢复系统的时候，特别注意的是要使用装有10.13+版本的U盘来启动。一般来说Macbook 2015初始的系统，都是10.13之前的系统，如果使用网络恢复模式，是无法在磁盘管理中找到nvme的硬盘的，我就碰到了这个问题。后面在更换使用10.14版本的U盘启动才可以识别到新的nvme硬盘。U盘制作方法可参考：如何创建可引导的 macOS 安装器 如果安装完成能正常启动，没有其他问题，那么到此，硬盘升级就完成。 二、开机黑屏的问题： 上面说到，我在第一次装好硬盘，开机启动的时候，是用网络恢复模式启动了，结果读取不到新的nvme硬盘。然后我把机器关机之后，重新用U盘启动，居然开机黑屏。具体症状为： 键盘灯正常亮； 开机有“dang”的一声响； A面Logo灯亮 屏幕黑屏 在尝试重置 NVRAM+SMC 之后，仍然没有任何效果。外接显示器在开机的时候按住 D，进入自检模式后，提示 显示器可能有问题，错误代码是 VFD001，此处有图： 看到显示器出问题，有点慌。但是我在拆机的时候，特别小心，就怕拆机把硬件拆出问题。在搜索了一些故障处理博文后，看到有不少人遇到了这个问题。根据这个威锋论坛的故障处理 自己动手丰衣足食，修理MacBook Pro 2015版屏幕，省了3000+软妹币 和这个博文 13″ MacBook Pro Retina – fixing no video issue by replacing display cable 。基本可以断定是触发了Mac的保护机制，导致了开机黑屏。 处理方法非常简单，按照上面两篇文章的方法，将主板上的电池断开连接，在将屏幕排线断开连接。等待大概2分钟后，在将屏幕排线和电池都连接好，重新开机。果然一切正常，顺利开机进入系统。此处当然也有图： 三、结语 至此，升级硬盘和开机黑屏全部处理完成。特别提醒的是，拆机的时候请特别小心，没有大力出奇迹。如果你没有把握请千万不要尝试。 参考： 2015 MacBookPro SSD硬盘更换 MacBook Pro (Retina, 13-inch, Early 2015)款升级Intel 760P SSD记录 如何创建可引导的 macOS 安装器 如果 Mac 无法开机的解决方法 自己动手丰衣足食，修理MacBook Pro 2015版屏幕，省了3000+软妹币 13″ MacBook Pro Retina – fixing no video issue by replacing display cable]]></content>
  </entry>
  <entry>
    <title><![CDATA[Prometheus联邦集群+Alertmanager电话报警配置示例说明]]></title>
    <url>%2F2019%2F08%2F30%2FPrometheus%E8%81%94%E9%82%A6%E9%9B%86%E7%BE%A4-Alertmanager%E7%94%B5%E8%AF%9D%E6%8A%A5%E8%AD%A6%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[目前公司有两个业务线，所以搭建了两套Kubernetes集群用来部署不同业务，每套集群内部都是用容器部署了一套Prometheus监控自身的业务。基于数据易于分析和预警及时的考虑，故整合两个集群的Prometheus数据到外层的一个Prometheus里，并增加高级别异常电话告警。联邦集群的原理这里不在赘述，各组件具体配置示例如下： 一、外层聚合Prometheus(二进制形式)配置示例: Prometheus配置示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# file: prometheus.yml# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: [&quot;localhost:9093&quot;]# Load rules once and periodically evaluate them according to the global &apos;evaluation_interval&apos;.rule_files: # 相关rule此处请根据需要自行配置 - &quot;/opt/prometheus/rules/*.rules&quot; - &quot;/opt/prometheus/rules/*.yaml&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&apos;s Prometheus itself.scrape_configs: # static_configs: # - targets: [&apos;localhost:9090&apos;] - job_name: &apos;federate&apos; # scrape_interval: 15s honor_labels: true metrics_path: &apos;/federate&apos; params: # 此处注意，job需要和收集端的job名称一致 &apos;match[]&apos;: - &apos;&#123;job=&quot;prometheus&quot;&#125;&apos; - &apos;&#123;job=&quot;etcd&quot;&#125;&apos; - &apos;&#123;job=~&quot;kubernetes-.*&quot;&#125;&apos; - &apos;&#123;job=~&quot;kube-.*&quot;&#125;&apos; # - &apos;&#123;job=~&quot;kubelet.*&quot;&#125;&apos; static_configs: # 需收集的地址 - targets: - &apos;192.168.7.74:9090&apos; - &apos;192.168.7.47:9090&apos;# file: prometheus.service[Unit]Description=PrometheusDocumentation=https://prometheus.io/After=network-online.targetWants=network-online.target[Service]Type=simpleExecStart=/opt/prometheus/prometheus \ --config.file=/opt/prometheus/prometheus.yml \ --storage.tsdb.path=/opt/prometheus/data \ --storage.tsdb.retention=168h \ # 数据持久化时间 --web.enable-lifecycle # 启用配置热更新 [Install]WantedBy=multi-user.target alertmanager配置示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# file: alertmanager.ymlglobal: smtp_smarthost: &quot;smtp.server.org:25&quot; smtp_from: &quot;k8salert@server.org&quot; smtp_auth_username: &quot;k8salert@server.org&quot; smtp_auth_password: &quot;password&quot; smtp_require_tls: falsetemplates: - &apos;/opt/alertmanager/templates/*.tmpl&apos; route: receiver: &apos;email_alert&apos; group_by: [&apos;alertname&apos;, &apos;instance&apos;, &apos;service&apos;, &apos;severity&apos;] # 聚合报警类别 group_wait: 10s # 聚合等待时间,超过这个时间开始发送报警 group_interval: 3m # 已经存在的group等待group_interval这个时间段看报警问题是否解决 repeat_interval: 5m # 再次报警间隔 routes: - match: # 报警媒介匹配规则 severity: critical # 匹配label receiver: &apos;multi_alert&apos;receivers: # 报警发送媒介 - name: &apos;email_alert&apos; # email email_configs: - to: &apos;aaa@server.com&apos; send_resolved: true - name: &apos;multi_alert&apos; # 多重媒介 webhook_configs: - send_resolved: true # 电话报警 url: &apos;http://192.168.7.105:8765/phoneWarn/callUp/v1/prome&apos; email_configs: # email - to: &apos;aaa@server.com&apos; send_resolved: true # file: alertmanager.service[Unit]Description=Prometheus Alertmanager ServiceWants=network-online.targetAfter=network.target[Service]Type=simpleExecStart=/opt/alertmanager/alertmanager \ --config.file /opt/alertmanager/alertmanager.yml \ --storage.path /opt/alertmanager/dataRestart=always[Install]WantedBy=multi-user.target 二、电话报警配置说明示例 电话报警原理：电话报警其实就是把prometheus发送给alertmanager的报警信息重新封装，推给已有的电话报警接口里(此处我们公司用的是封装的阿里云的电话接口) prometheus发送原始信息示例(需二次封装) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123; &quot;status&quot;: &quot;firing&quot;, &quot;groupLabels&quot;: &#123; &quot;alertname&quot;: &quot;pod_container_restart&quot; &#125;, &quot;groupKey&quot;: &quot;&#123;&#125;:&#123;alertname=\&quot;pod_container_restart\&quot;&#125;&quot;, &quot;commonAnnotations&quot;: &#123; &quot;description&quot;: &quot;Pod coredns-6fc7b84544-58ff6 in namespace kube-system has a container resstart for more than 5 times&quot; &#125;, &quot;alerts&quot;: [ &#123; &quot;status&quot;: &quot;firing&quot;, &quot;labels&quot;: &#123; &quot;k8s_app&quot;: &quot;kube-state-metrics&quot;, &quot;container&quot;: &quot;coredns&quot;, &quot;severity&quot;: &quot;Warning&quot;, &quot;kubernetes_namespace&quot;: &quot;kube-system&quot;, &quot;namespace&quot;: &quot;kube-system&quot;, &quot;instance&quot;: &quot;192.168.171.25:8080&quot;, &quot;job&quot;: &quot;kube-state-metrics&quot;, &quot;alertname&quot;: &quot;pod_container_restart&quot;, &quot;pod&quot;: &quot;coredns-6fc7b84544-58ff6&quot; &#125;, &quot;endsAt&quot;: &quot;0001-01-01T00:00:00Z&quot;, &quot;generatorURL&quot;: &quot;http://k8s-master-71:9090/graph?g0.expr=kube_pod_container_status_restarts_total+%3E+5&amp;g0.tab=1&quot;, &quot;startsAt&quot;: &quot;2019-08-27T19:22:54.730949237+08:00&quot;, &quot;annotations&quot;: &#123; &quot;description&quot;: &quot;Pod coredns-6fc7b84544-58ff6 in namespace kube-system has a container resstart for more than 5 times&quot; &#125; &#125; ], &quot;version&quot;: &quot;4&quot;, &quot;receiver&quot;: &quot;phone_alert&quot;, &quot;externalURL&quot;: &quot;http://k8s-master-71:9093&quot;, &quot;commonLabels&quot;: &#123; &quot;k8s_app&quot;: &quot;kube-state-metrics&quot;, &quot;container&quot;: &quot;coredns&quot;, &quot;severity&quot;: &quot;Warning&quot;, &quot;kubernetes_namespace&quot;: &quot;kube-system&quot;, &quot;namespace&quot;: &quot;kube-system&quot;, &quot;instance&quot;: &quot;192.168.171.25:8080&quot;, &quot;job&quot;: &quot;kube-state-metrics&quot;, &quot;alertname&quot;: &quot;pod_container_restart&quot;, &quot;pod&quot;: &quot;coredns-6fc7b84544-58ff6&quot; &#125;&#125; 电话报警功能封装代码示例： 123456789101112131415161718# url: http://192.168.7.105:8765/phoneWarn/callUp/v1/prome@app.route(api_prefix+&apos;prome&apos;, methods=[&apos;POST&apos;])def prome_alert(): content_name = &quot;您好&quot; phonenums = [&quot;131xxxxxxxx&quot;,&quot;141xxxxxxxx&quot;] alert_info = json.loads(request.data) call_content = &quot;容器集群&quot; + alert_info[&apos;groupLabels&apos;][&apos;alertname&apos;] alert_status = alert_info[&apos;status&apos;] if alert_status == &quot;firing&quot;: for phonenum in phonenums: params = &#123;&quot;taskname&quot;:&quot;&#123;&#125;&quot;.format(call_content), &quot;name&quot;:&quot;&#123;&#125;&quot;.format(content_name), &quot;phonenum&quot;: &quot;&#123;&#125;&quot;.format(phonenum)&#125; result = call_method.tts_call(phonenum, json.dumps(params)) # 自己封装的阿里云接口 elif alert_status == &quot;resolved&quot;: params = &#123;&quot;result&quot;: &quot;恢复不电话报警..&quot;&#125; logger.info(json.dumps(params, ensure_ascii=False)) return jsonify(json.loads(result)) 参考： Prometheus Alertmanager使用 prometheus-book prometheus document 将钉钉接入 Prometheus AlertManager WebHook Prometheus 和 Alertmanager实战配置]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用log-pilot收集ingress日志]]></title>
    <url>%2F2019%2F08%2F20%2F%E4%BD%BF%E7%94%A8log-pilot%E6%94%B6%E9%9B%86ingress%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[在Kubernetes集群内收集ingress日志，我们是直接使用了阿里开源的log-pilot做为采集端，将日志经logstash过滤，在汇聚到elasticsearch进行分析。各组件配置示例如下：一、log-pilot本质上也是一个日志的采集端，内部封装了filebeat和fluentd两种不同的采集工具，我们使用的是filebeat。 ingress-controller配置示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293# nginx-ingress-controller.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-ingress-controller namespace: kube-system labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: &quot;10254&quot; prometheus.io/scrape: &quot;true&quot; enable-vts-status: &quot;true&quot; spec: hostNetwork: true dnsPolicy: ClusterFirstWithHostNet nodeSelector: node-role.kubernetes.io/system: &apos;&apos; serviceAccountName: nginx-ingress-serviceaccount containers: - name: nginx-ingress-controller image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.24.1 imagePullPolicy: Always args: - /nginx-ingress-controller - --default-backend-service=$(POD_NAMESPACE)/default-http-backend - --configmap=$(POD_NAMESPACE)/nginx-configuration - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services - --udp-services-configmap=$(POD_NAMESPACE)/udp-services - --publish-service=$(POD_NAMESPACE)/ingress-nginx - --annotations-prefix=nginx.ingress.kubernetes.io securityContext: capabilities: drop: - ALL add: - NET_BIND_SERVICE # www-data -&gt; 33 runAsUser: 33 env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: aliyun_logs_ingress-nginx ## 注意此处的环境变量对接log-pilot(原理请见参考一) value: &quot;stdout&quot; ports: - name: http containerPort: 80 - name: https containerPort: 443 resources: limits: cpu: 200m memory: 500Mi requests: cpu: 200m memory: 500Mi livenessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 30 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 5 readinessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 log-pilot配置示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# log-pilot-system.yamlapiVersion: extensions/v1beta1kind: DaemonSetmetadata: name: log-pilot-system labels: app: log-pilot-system namespace: kube-systemspec: updateStrategy: type: RollingUpdate template: metadata: labels: app: log-pilot-system annotations: scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos; spec: hostNetwork: true containers: - name: log-pilot # 版本请参考https://github.com/AliyunContainerService/log-pilot/releases image: registry.cn-hangzhou.aliyuncs.com/acs/log-pilot:0.9.7-filebeat resources: limits: memory: 500Mi requests: cpu: 200m memory: 200Mi env: - name: &quot;NODE_NAME&quot; valueFrom: fieldRef: fieldPath: spec.nodeName # - name: &quot;LOGGING_OUTPUT&quot; # 直接将日志打到es里面 # value: &quot;elasticsearch&quot; # - name: &quot;ELASTICSEARCH_HOSTS&quot; # value: &quot;192.168.7.75&quot; # - name: &quot;LOGSTASH_PORT&quot; # value: &quot;9300&quot; - name: &quot;LOGGING_OUTPUT&quot; # 将日志打到logstash里面 value: &quot;logstash&quot; - name: &quot;LOGSTASH_HOST&quot; value: &quot;192.168.7.75&quot; - name: &quot;LOGSTASH_PORT&quot; value: &quot;5044&quot; volumeMounts: - name: sock mountPath: /var/run/docker.sock - name: root mountPath: /host readOnly: true - name: varlib mountPath: /var/lib/filebeat - name: varlog mountPath: /var/log/filebeat - name: localtime mountPath: /etc/localtime readOnly: true livenessProbe: failureThreshold: 3 exec: command: - /pilot/healthz initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 2 securityContext: capabilities: add: - SYS_ADMIN terminationGracePeriodSeconds: 30 # 是否允许部署到Master节点上 tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node-role.kubernetes.io/worker operator: NotIn values: - &apos;&apos; volumes: - name: sock hostPath: path: /var/run/docker.sock - name: root hostPath: path: / - name: varlib hostPath: path: /var/lib/filebeat type: DirectoryOrCreate - name: varlog hostPath: path: /var/log/filebeat type: DirectoryOrCreate - name: localtime hostPath: path: /etc/localtime 二、ingress其实在kubernetes集群内部就是作为nginx来使用的，故logstash的过滤规则可以参考nginx来写。示例如下： logstash配置示例： 123456789101112131415161718192021222324252627282930313233343536# filebeat.ymlinput &#123; beats &#123; port =&gt; 5044 &#125;&#125;filter &#123; grok &#123; patterns_dir =&gt; &quot;/opt/soft/logstash-6.2.4/config/patterns&quot; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;INGRESSACCESS_GET&#125;&quot; &#125; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;INGRESSACCESS_POST&#125;&quot; &#125; remove_field =&gt; [&quot;source&quot;, &quot;IPV6&quot;, &quot;IPV4&quot;, &quot;QUOTEDSTRING&quot;, &quot;upstream_response&quot;, &quot;URIPARAM&quot;] &#125; if [request] == &quot;/status.jsp&quot; &#123; drop&#123;&#125; &#125; urldecode &#123; all_fields =&gt; true # 显示中文 &#125;&#125;output &#123; elasticsearch &#123; #输出到elasticsearch中 hosts =&gt; [&quot;192.168.7.75:9200&quot;] #指定elasticsearch主机 document_type =&gt; &quot;log&quot; #设定Elasticsearch输出时的document的type字段，也可以用来给日志进行分类 template_overwrite =&gt; true #如果设置为true，模板名字一样的时候，新的模板会覆盖旧的模板 &#125;&#125; patterns配置示例(此规则可覆盖大多数请求日志，post比较特殊，可根据自己需求修改)： 123# patterns-ingressINGRESSACCESS_GET %&#123;IPORHOST:client_ip&#125; - \[%&#123;IPORHOST:x_forwarded_for&#125;\] - %&#123;DATA:client_identity&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \&quot;(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|-)\&quot; %&#123;NUMBER:http_code&#125; (?:%&#123;NUMBER:bytes_sent;long&#125;|-) (?:&quot;(?:%&#123;URI:referrer&#125;|-)&quot;) %&#123;QS:user_agent&#125; %&#123;NUMBER:request_length;long&#125; %&#123;NUMBER:response_time;double&#125; %&#123;DATA:upstream_proxy&#125; %&#123;NUMBER:upstream_bytes_sent;long&#125; %&#123;NUMBER:upstream_response_time&#125; %&#123;NUMBER:upstream_response&#125; %&#123;BASE16FLOAT:request_id&#125;INGRESSACCESS_POST %&#123;IPORHOST:client_ip&#125; - \[%&#123;IPORHOST:x_forwarded_for&#125;\] - %&#123;DATA:client_identity&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \&quot;(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|-)\&quot; %&#123;NUMBER:http_code&#125; (?:%&#123;NUMBER:bytes_sent;long&#125;|-) &quot;-&quot; %&#123;QS:user_agent&#125; %&#123;NUMBER:request_length;long&#125; %&#123;NUMBER:response_time;double&#125; %&#123;DATA:upstream_proxy&#125; %&#123;DATA:other&#125; 参考： 利用 Log-Pilot + Elasticsearch + Kibana 搭建 kubernetes 日志解决方案 Collect logs for docker containers Grok pattern for nginx ingress in Kubernetes Logstash 最佳实践 grok-patterns]]></content>
  </entry>
  <entry>
    <title><![CDATA[为Kubernetes配置Pod生命周期的附加操作程序]]></title>
    <url>%2F2019%2F08%2F08%2F%E4%B8%BAKubernetes%E9%85%8D%E7%BD%AEPod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%9A%84%E9%99%84%E5%8A%A0%E6%93%8D%E4%BD%9C%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[最近发现集群内的POD在删除的时候，不会自动清理某些自定义配置的网络信息。于是使用了Kubernets的一个功能，在删除或者启动POD的时候，去触发自定义的一些处理程序，避免POD在删除的时候遗留某些信息导致的集群异常。示例如下： Kubernetes在启动Container后立即发送postStart事件，并在Container终止之前立即发送preStop事件。 123456789101112131415apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;] preStop: exec: command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;nginx -s quit; while killall -0 nginx; do sleep 1; done&quot;] 需要注意的是，preStop并不会影响SIGTERM的处理，因此有可能preStop还没有执行完就收到SIGKILL导致容器强制退出。在这里可以设置terminationGracePeriodSeconds，让POD在删除的时候预留执行preStop的时间，来保证你的preStop事件完整处理。 12345678910111213141516apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;] preStop: exec: command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;nginx -s quit; while killall -0 nginx; do sleep 1; done&quot;] terminationGracePeriodSeconds: 60 # 增加此参数，默认时间为30s 参考： Attach Handlers to Container Lifecycle Events Kubernetes最佳实践：优雅的终止]]></content>
  </entry>
  <entry>
    <title><![CDATA[为Kubernetes集群内的Pod配置NFS存储]]></title>
    <url>%2F2019%2F08%2F03%2F%E4%B8%BAKubernetes%E9%9B%86%E7%BE%A4%E5%86%85%E7%9A%84Pod%E9%85%8D%E7%BD%AENFS%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[近一段时间在做容器化的项目，公司需要把nginx也放到kubernetes集群内，nginx有静态资源，如果在每个node节点都同步一份感觉太费劲，所以使用nfs挂载到pod内部使用。pod使用nfs存储有两种方法，介绍如下:一、在pod直接挂载nfs存储特别注意: 使用此种方法在pod里挂载nfs,务必要在pod所调度的节点上安装nfs-utils,否则无法挂载!!! 最近的几个Kubernetes大版本已经原生支持在pod内部直接挂载nfs存储，只需把volumes的类型改成nfs就行，示例如下： 12345678910111213141516171819kind: PodapiVersion: v1metadata: name: nfs-in-a-podspec: # hostNetwork: true containers: - name: app image: alpine volumeMounts: - name: nfs-volume mountPath: /var/nfs command: [&quot;/bin/sh&quot;] args: [&quot;-c&quot;, &quot;sleep 5000000000&quot;] volumes: - name: nfs-volume nfs: server: 192.168.7.107 path: /tmp/nfs_test 二、使用pvc挂载nfs存储 创建pv: 12345678910111213apiVersion: v1kind: PersistentVolumemetadata: name: my-nfs-sharespec: capacity: storage: 5Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain # 特别注意pv的回收策略,此处若需要pv删除后,nfs文件存在,则需要配置回收策略为:Retain nfs: server: 192.168.7.107 path: /tmp/nfs_test 创建pvc: 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: myapp-nfs namespace: defaultspec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi 创建pod: 123456789101112131415161718kind: PodapiVersion: v1metadata: name: nfs-in-a-podspec: # hostNetwork: true containers: - name: app image: alpine volumeMounts: - name: nfs-volume mountPath: /var/nfs command: [&quot;/bin/sh&quot;] args: [&quot;-c&quot;, &quot;sleep 5000000000&quot;] volumes: - name: nfs-volume persistentVolumeClaim: claimName: myapp-nfs 参考: pod使用nfs两种方法 pv回收策略]]></content>
  </entry>
  <entry>
    <title><![CDATA[两步清理Harbor磁盘空间]]></title>
    <url>%2F2019%2F08%2F03%2F%E4%B8%A4%E6%AD%A5%E6%B8%85%E7%90%86Harbor%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[测试环境的Harbor磁盘已经不堪重负,一天不知道多少个迭代测试包丢上面，清理已经刻不容缓。因公司使用Harbor版本比较老，无法在线清理，故需要两步清理：先删除不需要的tag，然后在使用garbage collection(GC)回收磁盘空间。Harbor已经在1.7.0版本支持在线清理空间. 一、清理不需要的镜像tag1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#! /usr/bin/env python3# -*- coding:utf-8 -*-# 此脚本基于时间排序，仅保留最新的15个tagimport requestsrequests.packages.urllib3.disable_warnings()class CleanHarbor: def __init__(self, user, password): self.user = user self.password = password self.base_url = &quot;https://registry.youdomain.com/&quot; self.login_url = self.base_url + &apos;login&apos; self.project_url = self.base_url + &apos;api/projects&apos; self.repo_url = self.base_url + &apos;api/repositories&apos; self.session = requests.Session() self.session.verify = False # 此处是个坑,harbor源码auth部分的username是principal,故params参数必须是principal,否则会401 self.session.post(self.login_url, params=&#123;&quot;principal&quot;: self.user, &quot;password&quot;: self.password&#125;) def get_project(self): project_info = [] harbor_info = self.session.get(self.project_url).json() for project in harbor_info: info = &#123;&#125; info[&apos;project_id&apos;] = project[&apos;project_id&apos;] info[&apos;project_name&apos;] = project[&apos;name&apos;] project_info.append(info) return project_info def get_delete_repo(self): project_info = self.get_project() delete_reponame = [] for project_id in project_info: repo_info = self.session.get(self.repo_url, params=&#123;&quot;project_id&quot;: project_id[&apos;project_id&apos;]&#125;).json() for repo in repo_info: if repo[&apos;tags_count&apos;] &gt; 15: delete_reponame.append(repo[&apos;name&apos;]) return delete_reponame def delete_repo_tag(self): delete_reponame = self.get_delete_repo() for repo_name in delete_reponame: tag_url = self.repo_url + &quot;/&quot; + repo_name + &quot;/tags&quot; tags = self.session.get(tag_url).json() tags_sort = sorted(tags, key=lambda tags: tags[&quot;created&quot;]) del_tags = tags_sort[0:len(tags_sort) - 15] for tag in del_tags: del_repo_tag_url = tag_url + &quot;/&quot; + tag[&apos;name&apos;] result = self.session.delete(del_repo_tag_url) if result.status_code == 200: print(&apos;&#123;&#125;:&#123;&#125; tag删除成功..&apos;.format(repo_name, tag[&apos;name&apos;])) print(&quot;所有tag删除完成...&quot;)if __name__ == &quot;__main__&quot;: Harobr = CleanHarbor(&apos;admin&apos;, &apos;Harbor12345&apos;) Harobr.delete_repo_tag() 二、使用garbage collection(GC)机制删除镜像的实际文件12345678910111213# 先停止harbor服务docker-compose down# 使用gc回收磁盘空间(GC使用“标记-清理”法)# 第一步，标记:registry扫描元数据，元数据能够索引到的blob标记为不能删除# 第二步，清理:registry扫描所有blobs，如果该blob没有被标记，则删除它# 注意此处的registry-photon,请保持和你的版本一致,如下图image_name=$(docker ps | grep registry | grep photon | awk -F &quot; &quot; &apos;&#123;print $2&#125;&apos;)docker run -it --name gc --rm --volumes-from registry $&#123;image_name&#125; garbage-collect /etc/registry/config.yml# 启动Harbordocker-compose start 参考: tag清理脚本 gc回收步骤 harbor user guide]]></content>
  </entry>
  <entry>
    <title><![CDATA[mega网盘命令行模式使用说明]]></title>
    <url>%2F2019%2F07%2F27%2Fmega%E7%BD%91%E7%9B%98%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A8%A1%E5%BC%8F%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[之前买了一台小鸡是打算做梯子用的，但是搭的梯子质量并不是很好，时断时续。于是想着不能浪费就在上面搭了一个transmission用来下载bt。毕竟是台小鸡，网络传输还是慢，下载的东西传到本地机器还是很慢，于是就用mega代理了一下，先上传到mega上，然后在下载到本地，所以使用mega命令行来操作。mega网盘确实蛮好用的，免费的也基本够用了 mega命令行使用： 基本操作： 123456789101112131415# 先进入mega命令行模式# mega-cmd# 以下所有操作全是都是在mega-cmd命令行模式进行# 使用login命令，登录成功不会显示成功之类的信息，会直接进入默认用户的目录,下图login yourname@mail.com|username password # 登录logout # 登出quit|exit # 退出# 基础操作(同linux)cd /pathname # 进入目录ls /pathname # 查看目录文件mkdir /pathname # 创建文件夹... 常用操作： 1234567891011121314151617181920212223# 上传put [-c] [-q] [--ignore-quota-warn] localfile [localfile2 localfile3 ...] [dstremotepath]# 后面若不跟远程路径,则默认传到当前所在的远程路径(可使用-c创建远程路径)put /root/test.mp4 /movies# 下载get [-m] [-q] [--ignore-quota-warn] exportedlink#key|remotepath [localpath]# 若本地文件夹和远程文件夹,可跟-m参数合并本地文件夹get /MEGAsync/Kubernetes.pdf /root/# 删除rm [-r] [-f] remotepath# -rf强制删除rm /MEGAsync/Kubernetes.pdf# 同步sync [localpath dstremotepath| [-dsr] [ID|localpath]# -d id删除同步、-s id停止、-r id重新开始、啥都不加展示当前同步任务sync /var/lib/transmission/Downloads/ /movies # transferstransfers [-c TAG|-a] | [-r TAG|-a] | [-p TAG|-a] [--only-downloads | --only-uploads] [SHOWOPTIONS] 参考： mega-cmd mega-cmd UserGuide]]></content>
  </entry>
  <entry>
    <title><![CDATA[搭建DNS管理平台的一些注意要点]]></title>
    <url>%2F2019%2F07%2F20%2F%E6%90%AD%E5%BB%BADNS%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%B3%A8%E6%84%8F%E8%A6%81%E7%82%B9%2F</url>
    <content type="text"><![CDATA[公司内部一直缺少一个管理DNS的平台，故搭建了一个WEB页面，用来管理内部的DNS解析。期间遇到的一些坑，分享一下。一、BIND-DNS主从模式选择 如果使用web页面来管理DNS，其实BIND-DNS最方便的是主和从都采用数据库作为后端数据存储。主DNS使用主数据库，然后从DNS使用从数据库。然后web页面修改了主数据库后，那么从数据库也会实时同步更新。达到DNS主从同步的目的； 采用以上方法虽然简单，但是一个致命的问题。就是如果使用数据库作为DNS的后端存储，那么DNS的解析速度是远远不如使用文件作为后端数据存储的(对比下图)； 综上，故建议主DNS使用数据库存储，然后web页面管理主DNS。而从DNS使用文件存储，每次修改主DNS数据库，自动同步数据到从DNS的文件上，所有的主机使用从DNS作为DNS服务器，达到管理方便和解析快速的双重目的； 一张解析速度对比图： 二、DNS主从同步实时处理 一般来说，DNS主从同时使用相同模式，基本不存在数据不同步的问题。但是如果主从使用不同模式部署，就会出现数据不同步的异常； 采用不同模式，在主DNS修改了数据之后，从DNS是根据设定的refresh值来同步的。如果解析可接受延迟，那么可把refresh值修改的短一点，实现主从同步； 如果接受不了延迟，那么可使用rndc命令手动强制刷新，在修改了主DNS的数据后，强制同步从DNS，示例代码如下： 1234567891011# 手动强制refresh记录，不等300sdef record_refresh(domain_name): DNS_slave_ip = settings.DNS_SLAVE_IP result_code = [] for slave_ip in DNS_slave_ip: command = &apos;rndc -s &#123;&#125; -p 953 -k rndc.key refresh &quot;&#123;&#125;&quot;&apos;.format(slave_ip, domain_name) result_code.append(subprocess.call(command, shell=True)) for i in range(len(result_code)): if result_code[i] != 0: return False print(&apos;refresh success..&apos;) 三、serial导致的不同步 serial是SOA默认参数，这个参数非常重要，当从DNS需要refresh解析的时候，会先去查下serial的值是否改变(增加)，若serial有增加，则会refresh当前从DNS的解析记录，反之则不进行任何变动； 当你在web页面编辑DNS解析的时候，不管是增加、删除，或者修改，都需要变动serial的值，每变动一次都需要将数值其增加； 参考： 速度对比图：http://bind-dlz.sourceforge.net/perf_tests.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[Centos6.10 安装Docker 17.03.2-ce]]></title>
    <url>%2F2019%2F07%2F16%2FCentos6-10-%E5%AE%89%E8%A3%85Docker-17-03-2-ce%2F</url>
    <content type="text"><![CDATA[前两天需要在Centos6上面封装docker镜像需要安装docker，但是发现在Centos6上安装docker只能安装docker 1.7.1版本。此版本推送镜像到harbor验证有问题，故需要升级docker版本到17.03.2-ce。特别注意,编译安装过程极度依赖梯子,否则安装很难成功! 一、升级内核 在centos6上安装docker17.03.2，需要先将内核升级到3.10版本(未考证?)，故直接安装最新稳定版内核 123456rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpmyum install kernel-lt -ysed -i &apos;s/default=1/default=0/g&apos; /etc/grub.confrebootuname -sr #Linux 4.4.185-1.el6.elrepo.x86_64 二、安装依赖docker环境 docker 17.03.2安装全部都是在docker里面完成的，故需要安装一个老版本的docker，才能编译安装17.03版本 1234567891011121314# 安装1.7.1版本rpm -ivfh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpmyum install https://get.docker.com/rpm/1.7.1/centos-6/RPMS/x86_64/docker-engine-1.7.1-1.el6.x86_64.rpmdocker version # version: 1.7.1#下载1.9.1然后替换curl -sSL -O https://get.docker.com/builds/Linux/x86_64/docker-1.9.1chmod +x docker-1.9.1mv docker-1.9.1 /usr/bin/docker service docker restartdocker version # version: 1.9.1 三、安装依赖环境123456789101112131415yum install git make -y#Docker使用Golang开发wget https://dl.google.com/go/go1.10.linux-amd64.tar.gztar xzf go1.10.linux-amd64.tar.gz -C /usr/localmkdir /usr/local/gopackage vi /etc/profile#在profile中加入下面的环境变量，PATH如果原来就有请自行合并GOROOT=/usr/local/goGOPATH=/usr/local/gopackagePATH=$PATH:$GOROOT/bin:$GOPATH/binexport GOROOT GOPATH PATH source /etc/profile 四、安装docker123456789101112131415161718192021# 修改git缓存,防止git clone中断git config --global http.postBuffer 524288000git clone https://github.com/moby/mobycd moby# 选择17.03.2git checkout v17.03.2-ce# 编辑Dockerfilevim Dockerfile# 修改130为:RUN curl -fsSL &quot;https://golang.org/dl/go$&#123;GO_VERSION&#125;.linux-amd64.tar.gz&quot; \# 建议在第一个git clone之前RUN一个代理，否则git clone大概率失败RUN git config --global http.https://github.com.proxy socks5://127.0.0.1:1080 \make build # 此步骤极度耗时，且因为某种原因，安装过程极易中断make binarymake install 五、移除旧版本，指向新版本123456789101112131415161718192021222324#卸载旧的dockeryum remove docker-engine* -y#清理下遗留的文件rm -rf /var/lib/docker/*#docker 配置文件wget https://raw.githubusercontent.com/moby/moby/master/contrib/init/sysvinit-redhat/docker.sysconfig -O /etc/sysconfig/docker#docker init启动文件wget https://raw.githubusercontent.com/moby/moby/master/contrib/init/sysvinit-redhat/docker -O /etc/init.d/docker#修改启动文件中dockerd的位置sed -i &quot;27s#usr/bin#usr/local/bin#g&quot; /etc/init.d/docker#修改环境变量，覆盖functions脚本中的PATH，防止无法找到docker-container等程序sed -i &quot;23s#functions#functions\nexport PATH=/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/bin#g&quot; /etc/init.d/docker#启动service docker restart#查看版本ln -s /usr/local/bin/docker /usr/bin/dockerdocker version 六、完成验证 参考： 安装步骤参考：CentOS6 安装最新版Docker 17.03——自给自足，老树逢春]]></content>
  </entry>
  <entry>
    <title><![CDATA[DNS各类型互斥关系说明]]></title>
    <url>%2F2019%2F07%2F14%2FDNS%E5%90%84%E7%B1%BB%E5%9E%8B%E4%BA%92%E6%96%A5%E5%85%B3%E7%B3%BB%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[前段时间完成了公司内部DNS解析平台的搭建，内里有许多坑，其中一个的就是DNS各种类型的互斥关系，简单说明如下。DNS有下列几种类型： A记录： 将域名指向一个IPv4地址（例如：100.100.100.100），需要增加A记录; CNAME记录： 如果将域名指向一个域名，实现与被指向域名相同的访问效果，需要增加CNAME记录。这个域名一般是主机服务商提供的一个域名; MX记录： 建立电子邮箱服务，将指向邮件服务器地址，需要设置MX记录。建立邮箱时，一般会根据邮箱服务商提供的MX记录填写此记录; NS记录： 域名解析服务器记录，如果要将子域名指定某个域名服务器来解析，需要设置NS记录; TXT记录： 可任意填写，可为空。一般做一些验证记录时会使用此项，如：做SPF（反垃圾邮件）记录; AAAA记录： 将主机名（或域名）指向一个IPv6地址（例如：ff03:0:0:0:0:0:0:c1），需要添加AAAA记录; SRV记录： 添加服务记录服务器服务记录时会添加此项，SRV记录了哪台计算机提供了哪个服务。格式为：服务的名字.协议的类型（例如：_example-server._tcp）; SOA记录： SOA叫做起始授权机构记录，NS用于标识多台域名解析服务器，SOA记录用于在众多NS记录中那一台是主服务器; PTR记录： PTR记录是A记录的逆向记录，又称做IP反查记录或指针记录，负责将IP反向解析为域名; 显性URL转发记录： 将域名指向一个http(s)协议地址，访问域名时，自动跳转至目标地址。例如：将www.liuht.cn显性转发到www.itbilu.com后，访问www.liuht.cn时，地址栏显示的地址为：www.itbilu.com; 隐性UR转发记录L： 将域名指向一个http(s)协议地址，访问域名时，自动跳转至目标地址，隐性转发会隐藏真实的目标地址。例如：将www.liuht.cn显性转发到www.itbilu.com后，访问www.liuht.cn时，地址栏显示的地址仍然是：www.liuht.cn; 互斥关系说明： 任何类型的主机记录，都不能与cname类型的主机记录冲突；NS类型的主机记录自身不冲突，但与其他记录都冲突(主机记录为@除外)；A,MX,TXT类型的主机记录自身不冲突； A类型记录值只能为ip地址，CNAME类型记录值只能为域名，NS类型记录值和TXT类型记录值可以为任意值，MX类型记录值只能为ip地址和域名 TXT主机记录可以有特殊字符（格式为域名），其他类型的主机记录不能有特殊字符; 参考： DNS类型参考：https://itbilu.com/other/relate/EyxzdVl3.html 互斥图参考：https://www.cloudxns.net/Support/detail/id/20.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F07%2F14%2Ftest%2F</url>
    <content type="text"><![CDATA[test blog update]]></content>
  </entry>
  <entry>
    <title><![CDATA[ubuntu dns显示为127.0.0.1的处理办法]]></title>
    <url>%2F2018%2F07%2F04%2Fubuntu-dns%E6%98%BE%E7%A4%BA%E4%B8%BA127-0-0-1%E7%9A%84%E5%A4%84%E7%90%86%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[新装一台Ubuntu虚拟机测试dhcp服务器，发现ubuntu的dns显示为：127.0.0.1。有点疑惑，google之，找到原因。 ubuntu下有一个本地的dns服务叫做dnsmasq，它是由NetworkManager控制的 1ps -ef | grep dnsmasq 执行上面命令，你就可以看到它监听的本地地址，–listen-address=127.0.1.1 (ubuntu12.04及之前的版本 是 127.0.0.1)， 这个地址是一个本地回环地址，而你真实的dns服务器地址，是被这个服务管理维护着的，管理方式如下： 1local process -&gt; local dnsmasq -&gt; router -&gt; ISP dns 若需要看到真实的DNS地址，可以这么做： 12345678910111213141516sudo vi /etc/NetworkManager/NetworkManager.conf[main]plugins=ifupdown,keyfile,ofono#dns=dnsmasq // 注释此行sudo service network-manager restartnslookup baidu.comServer: 192.168.20.21Address: 192.168.20.21#53Non-authoritative answer:Name: baidu.comAddress: 220.181.57.216Name: baidu.comAddress: 123.125.115.110 如果没有nslookup命令，那么你需要安装bind-utils 1sudo apt install bind-utils 参考链接： ubuntu中 etc resolv.cnf中的127.0.1.1是什么地址 Connection info shows correct DNS but resolvconf does not show the same]]></content>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes强制删除一直处于Terminating状态的pod，namespace]]></title>
    <url>%2F2018%2F06%2F26%2FKubernetes%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8ETerminating%E7%8A%B6%E6%80%81%E7%9A%84pod%EF%BC%8Cnamespace%2F</url>
    <content type="text"><![CDATA[手动搭建的Kubernetes，使用原生的Dashboard，感觉不舒服，于是使用Rancher2.0代理了Kubernetes的管理web页面。因未知原因，Rancher服务无法启用，删除Rancher依赖的namespace（cattle-system），状态一直是Terminating。此为背景。解决方法： 可使用kubectl中的强制删除命令12345# 删除PODkubectl delete pod PODNAME --force --grace-period=0# 删除NAMESPACEkubectl delete namespace NAMESPACENAME --force --grace-period=0 若以上方法无法删除，可使用第二种方法，直接从ETCD中删除源数据(这是一种最暴力的方式，我们不建议直接操作etcd中的数据，在操作前请确认知道你是在做什么。)12345# 删除default namespace下的pod名为pod-to-be-deleted-0ETCDCTL_API=3 etcdctl del /registry/pods/default/pod-to-be-deleted-0# 删除需要删除的NAMESPACEetcdctl del /registry/namespaces/NAMESPACENAME 参考链接： Kubernetes使用技巧]]></content>
  </entry>
  <entry>
    <title><![CDATA[kubernetes介绍]]></title>
    <url>%2F2018%2F06%2F13%2Fkubernetes%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[初步介绍: Kubernetes是Google开源的容器集群管理系统，其提供应用部署、维护、 扩展机制等功能，利用Kubernetes能方便地管理跨机器运行容器化的应用，其主要功能如下： 使用Docker对应用程序包装(package)、实例化(instantiate)、运行(run)。 以集群的方式运行、管理跨机器的容器。 解决Docker跨机器容器之间的通讯问题。 Kubernetes的自我修复机制使得容器集群总是运行在用户期望的状态。 Kubernetes主要概念: Node：是kubernetes集群的工作负载节点。Master为其分配工作，当某个Node宕机时，Master会将其工作负载自动转移到其他节点。 Pods：Pod是Kubernetes的基本操作单元，把相关的一个或多个容器构成一个Pod，通常Pod里的容器运行相同的应用。Pod包含的容器运行在同一个Minion(Host)上，看作一个统一管理单元，共享相同的volumes和network namespace/IP和Port空间。Kubernetes为每个Pod都分配了唯一的IP地址，称之为PodIP，一个Pod里的多个容器共享PodIP地址。 Services：Services也是Kubernetes的基本操作单元，是真实应用服务的抽象，每一个服务后面都有很多对应的容器来支持，通过Proxy的port和服务selector决定服务请求传递给后端提供服务的容器，对外表现为一个单一访问接口，外部不需要了解后端如何运行，这给扩展或维护后端带来很大的好处。 Replication Controllers(副本控制器)：Replication Controller确保任何时候Kubernetes集群中有指定数量的pod副本(replicas)在运行， 如果少于指定数量的pod副本(replicas)，Replication Controller会启动新的Container，反之会杀死多余的以保证数量不变。Replication Controller使用预先定义的pod模板创建pods，一旦创建成功，pod 模板和创建的pods没有任何关联，可以修改pod模板而不会对已创建pods有任何影响，也可以直接更新通过Replication Controller创建的pods。对于利用pod模板创建的pods，Replication Controller根据label selector来关联，通过修改pods的label可以删除对应的pods。 Namespace: 命名空间为Kubernetes集群提供虚拟的隔离作用，Kubernetes集群初始有两个命名空间，分别是默认命名空间default和系统命名空间kube-system，除此以外，管理员可以可以创建新的命名空间满足需要。 Volume：Kubernetes的存储卷的生命周期和作用范围是一个Pod。每个Pod中声明的存储卷由Pod中的所有容器共享。Kubernetes支持非常多的存储卷类型，特别的，支持多种公有云平台的存储，包括AWS，Google和Azure云；支持多种分布式存储包括GlusterFS和Ceph；也支持较容易使用的主机本地目录hostPath和NFS。 Kubernetes主要构件:Master： Kubernetes API Server:作为Kubernetes系统的入口，其封装了核心对象的增删改查操作，以RESTful API接口方式提供给外部客户和内部组件调用。维护的REST对象持久化到Etcd中存储。 Kubernetes Scheduler:为新建立的Pod进行节点(node)选择(即分配机器)，负责集群的资源调度。组件抽离，可以方便替换成其他调度器。 Kubernetes Controller负责执行各种控制器，目前已经提供了很多控制器来保证Kubernetes的正常运行。 Node: Kubelet：主要包含容器管理，镜像管理，Volume管理等。同时kubelet也是一个rest服务，和pod相关的命令操作都是通过调用接口实现的.Kubelet会从Kubernetes API Server接收Pod的创建请求，启动和停止容器，监控容器运行状态并汇报给Kubernetes API Server。 Kube-proxy：负责为Pod创建代理服务，Kubernetes Proxy会从Kubernetes API Server获取所有的Service信息，并根据Service的信息创建代理服务，实现Service到Pod的请求路由和转发，从而实现Kubernetes层级的虚拟转发网络。用于实现Kubernetes的service机制。提供一部分SDN功能以及集群内部的智能LoadBalancer Docker：Node上需要运行容器服务 Etcd：一款分布式的一致性KV存储，主要用于共享配置和服务发现 作为配置中心和存储服务，保存了所有组件的定义以及状态，Kubernetes的多个组件之间的互相交互也主要通过etcd。在k8s中，所有数据的存储以及操作记录都在etcd中进行存储，所以对于k8s集群来说，etcd是相当重要的，一旦故障，可能导致整个集群的瘫痪或者数据丢失。 网络插件flannel、对于其它网络插件需要用到etcd存储网络的配置信息 kubernetes本身，包括各种对象的状态和元信息配置 Kubectl 通过客户端的kubectl命令集操作，API Server响应对应的命令结果，从而达到对kubernetes集群的管理。 主流网络插件介绍 flannel：flannel是coreos为k8s设计的一个非常简洁的多节点3层容器网络互联方案。 flannel旨在解决不同host上的容器网络互联问题，大致原理是每个 host 分配一个 subnet，容器从此 subnet 中分配 IP，这些 IP 可以在 host 间路由，容器间无需 NAT 和 port mapping 就可以跨主机通信。每个 subnet 都是从一个更大的 IP 池中划分的，flannel 会在每个主机上运行一个叫 flanneld 的 agent，其职责就是从池子中分配 subnet。为了在各个主机间共享信息，flannel 用 etcd（如果是k8s集群会直接调用k8s api）存放网络配置、已分配的 subnet、host 的 IP 等信息。节点间的通信有以下多种backen支持。 VXLAN：推荐配置，利用内核级别的VXLAN来封装host之间传送的包。host-gw：对于性能有要求的推荐配置，但是不支持云环境。通过在host的路由表中直接创建到其他主机 subnet 的路由条目，从而实现容器跨主机通信。要求所有host在二层互联。 udp：默认模式，通常用于debug，或以上两种条件都不具备。.png) calico：calico是一个比较完整的项目，专为云环境设置，且比较注重安全性，也就是网络隔离，ACL控制等都是可以实现。 calico是一个纯三层的数据中心网络方案，实现类似于flannel host-gw,不过它没有复用docker 的docker0 bridge，而是自己实现的。 Calico在每一个计算节点利用Linux Kernel实现了一个高效的vRouter来负责数据转发，而每个vRouter通过BGP协议负责把自己上运行的workload的路由信息像整个Calico网络内传播——小规模部署可以直接互联，大规模下可通过指定的BGP route reflector来完成。 Calico基于iptables还提供了丰富而灵活的网络Policy，保证通过各个节点上的ACLs来提供Workload的多租户隔离、安全组以及其他可达性限制等功能。 对于有IP限制的host，也可以使用calico的IPIP方案（overlay方式）。 整体系统架构图]]></content>
  </entry>
  <entry>
    <title><![CDATA[Centos&Ubuntu安装Docker-17.03.02版本问题及解决]]></title>
    <url>%2F2018%2F06%2F07%2FCentos-Ubuntu%E5%AE%89%E8%A3%85Docker-17-03-02%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[最近在尝试容器化的项目，使用rancher部署kubernetes，奈何kubernetes1.8只支持特定的版本（1.12.6，1.13.1，17.03.02），此为前提。Centos安装部署(此Centos版本为7+)： 目前docker版本已更新为18.05.0-ce，17.03.02建议手动安装。 手动安装17.03.02，需先安装docker-ce-selinux-17.03.2.ce，要不会报error，无法安装。 1sudo yum install -y https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch.rpm 安装完成后可安装17.03.02。 1sudo yum install -y https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm 你也可以直接使用国内yum安装(推荐) 12345678sudo yum install -y yum-utilssudo yum-config-manager \--add-repo \https://download.daocloud.io/docker/linux/centos/docker-ce.reposudo yum install -y -q --setopt=obsoletes=0 docker-ce-17.03.2.ce* docker-ce-selinux-17.03.2.ce*sudo systemctl enable dockersudo systemctl start dockersudo service docker status Ubuntu安装部署 直接使用国内源安装123456789101112131415sudo apt-get updatesudo apt-get install -y \apt-transport-https \ca-certificates \curl \software-properties-commoncurl -fsSL https://download.daocloud.io/docker/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \&quot;deb [arch=$(dpkg --print-architecture)] https://download.daocloud.io/docker/linux/ubuntu \$(lsb_release -cs) \stable&quot;sudo apt-get updatesudo apt-get install -y -q docker-ce=17.03.2*sudo service docker startsudo service docker status 服务检查 检查docker是否安装成功 123456sudo groupadd docker #建立docker组sudo usermod -aG docker $USER # 加入docker组# 退出当前终端并重新登录，进行如下测试docker versiondocker infodocker run hello-world 手动安装需要增加开机自启 1sudo systemctl enable docker 镜像加速 国内大家都懂的原因，添加阿里云的镜像加速器。12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123;&quot;registry-mirrors&quot;: [&quot;https://yourself.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 一点怨念：国内大多数博客教程（互相抄？）都是让你添加docker的官方源来安装17.03.02，也不知道是到底有没有测试。目前的网络环境来说，docker官方源是很难连上的，当然你走代理另说。善用google，禁用百度。 参考： https://blog.csdn.net/CSDN_duomaomao/article/details/79019764 http://www.showerlee.com/archives/2200 http://jasmine-abbs.com/docker-daemon/ 安装 Docker]]></content>
  </entry>
  <entry>
    <title><![CDATA[终端+git设置代理联网]]></title>
    <url>%2F2018%2F05%2F30%2F%E7%BB%88%E7%AB%AF-git%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E8%81%94%E7%BD%91%2F</url>
    <content type="text"><![CDATA[天朝的网络环境对技术人员实在是不友好，还好ShadowsocksX-NG已支持sock5，http两种代理协议。设置终端代理 在 .bashrc 或 .zshrc 中设置如下内容12345678910#sock代理alias setproxy=&quot;export ALL_PROXY=socks5://127.0.0.1:1080&quot;alias unsetproxy=&quot;unset ALL_PROXY&quot;#http代理alias setproxy=&quot;export ALL_PROXY=http://127.0.0.1:8035&quot;alias unsetproxy=&quot;unset ALL_PROXY&quot;#测试curl ip.cn 设置git代理 可以编辑~/.gitconfig或者直接执行下面命令1234567891011#sock代理git config --global http.proxy &apos;socks5://127.0.0.1:1080&apos; git config --global https.proxy &apos;socks5://127.0.0.1:1080&apos;#http代理git config --global http.proxy &quot;http://127.0.0.1:8035&quot;git config --global https.proxy &quot;http://127.0.0.1:8035&quot;#取消设置git config --global --unset http.proxygit config --global --unset https.proxy 参考： 设置 socks5/http 代理，可用于git和shell终端 ShadowsocksX-NG下载]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux NFS挂载失败两种异常处理]]></title>
    <url>%2F2018%2F05%2F20%2Flinux-NFS%E6%8C%82%E8%BD%BD%E5%A4%B1%E8%B4%A5%E4%B8%A4%E7%A7%8D%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[最近在研究kubernetes，测试使用NFS作为k8s的文件系统。部署过程中的问题，归纳一下。 报错‘clnt_create: RPC: Program not registered’，解决如下：123456789# 请按顺序执行systemctl stop rpcbindsystemctl stop nfssystemctl start rpcbindsystemctl start nfssystemctl status rpcbind &amp;&amp; systemctl status nfs#测试mount -t nfs 192.168.7.13:/datadir /mnt 报错‘mount.nfs: access denied’，解决如下：1234567# 保证挂载client节点ip在server配置指定的网段内cat /etc/exports/dirdata 192.168.7.0/24(rw,no_root_squash,sync)# 如果指定的是192.168.7.0/24，那么client的ip也需要在这个网段内#测试mount -t nfs 192.168.7.13:/datadir /mnt 参考链接： NFS-mount 如何进行跨服务器文件挂载 nfs实验错误提示clnt_create: RPC: Program not registered SuSE linux NFS挂载失败案例处理：mount.nfs: access denied]]></content>
  </entry>
  <entry>
    <title><![CDATA[cassandra建表异常处理]]></title>
    <url>%2F2018%2F03%2F08%2Fcassandra%E5%BB%BA%E8%A1%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[今天需要在cassandra建立一个新表用作英文spu匹配，报错如下：123Warning: schema version mismatch detected, which might be caused by DOWN nodes; if this is not the case, check the schema versions of your nodes in system.local and system.peers. OperationTimedOut: errors=&#123;&#125;, last_host=host 初步判断应该是cassandra节点数据异常，使用nodetool工具修复之，再次建表无异常。1./nodetool repair cassandra还是建议定时repair，防止出现数据异常. 参考： Cassandra - Every command issued in CQLSH throws errors nodetool repair]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用百度翻译API翻译数据示例]]></title>
    <url>%2F2018%2F03%2F02%2F%E4%BD%BF%E7%94%A8%E7%99%BE%E5%BA%A6%E7%BF%BB%E8%AF%91API%E7%BF%BB%E8%AF%91%E6%95%B0%E6%8D%AE%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[公司使用电商分析平台需要英文版，商品spu数据需要翻译。调研几个平台的翻译API：有道，google，百度，最后选择百度（并不是因为百度翻译的好，而是百度不要钱！）示例代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#/usr/bin/env python# -*- coding:utf-8 -*-import jsonimport httplibimport md5import urllibimport randomappid = '' secretKey = ''httpClient = NonefromLang = 'zh'toLang = 'en'infos = [] # 待翻译results = &#123;&#125;def make_file(filename): num = 0 with open(filename, 'w+') as f: for info in infos: myurl = '/api/trans/vip/translate' q = info.strip() salt = random.randint(32768, 65536) sign = appid+q+str(salt)+secretKey m1 = md5.new() m1.update(sign) sign = m1.hexdigest() myurl = myurl+'?appid='+appid+'&amp;q='+urllib.quote(q)+'&amp;from='+fromLang+'&amp;to='+toLang+'&amp;salt='+str(salt)+'&amp;sign='+sign try: httpClient = httplib.HTTPConnection('api.fanyi.baidu.com') httpClient.request('GET', myurl) response = httpClient.getresponse() result = json.loads(response.read())['trans_result'][0]['dst'].encode('utf-8') results["data"] = result line = json.dumps(results) f.write(line + '\n') num += 1 if num % 1000 == 0: print('success &#123;&#125;'.format(num)) except Exception, e: print e finally: if httpClient: httpClient.close()if __name__ == "__main__": filename = 'trans.json' make_file(filename) 翻译质量并不算高，而且没办法保持翻译之前的数据分割格式。不要钱，凑合着用吧。参考： 百度通用翻译API技术文档 脚本下载]]></content>
  </entry>
  <entry>
    <title><![CDATA[二分查找和常用排序Python实现]]></title>
    <url>%2F2018%2F02%2F25%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E5%92%8C%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8FPython%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[明白查找和排序基本原理，但是一直手写不出来。手打一遍，帮助记忆。 二分查找： 12345678910111213141516#!/usr/bin/env python3# -*- coding: utf-8 -*-# author: nemo_chen# 二分查找Python实现def binary_search(arr, key): start = arr[0] end = arr[-1] while start &lt;= end: mid = start + (end - start) / 2 if arr[mid] &gt; key: start = mid -1 elif arr[mid] &lt; key: start = mid + 1 else: return mid 常用排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#!/usr/bin/env python3# -*- coding: utf-8 -*-# author: nemo_chen# 几种常用排序Python实现# http://blog.csdn.net/mrlevo520/article/details/77829204# 冒泡def bubbleSort(arr): l = len(arr) for i in range(l): for j in range(l-1): if arr[j] &gt; arr[j+1]: arr[j], arr[j+1] = arr[j+1], arr[j] return arr# 选择# method one:def selectSort(arr): l = len(arr) for i in range(l): min_index = i for j in range(i+1, l): if arr[j] &lt; arr[min_index]: min_index = j arr[i], arr[min_index] = arr[min_index], arr[j] return arr # method two:def selectSort(arr): l = len(arr) for i in range(l): for j in range(l - i): if arr[i] &gt; arr[j+i]: arr[i], arr[i+j] = arr[i+j], arr[i] return arr# 快速def quickSort(arr): if len(arr) &lt; 2: return arr else: basic = arr[0] less = [i for i in arr[1:] if i &lt; basic] more = [i for i in arr[1:] if i &gt; basic] return quickSort(less) + [basic] + quickSort(more)# 插入def insertSort(arr): l = len(arr) for i in range(1, l): for j in range(i): if arr[i] &lt; arr[j]: arr.insert(j, arr[i]) arr.pop(i+1) break return arr# 希尔def shellSort(arr): l = len(arr) basic = l / 2 while basic &gt; 0: for i in range(basic, l): temp = arr[i] j = i while j &gt;= basic and arr[j - basic] &gt; temp: arr[j] = arr[j - basic] j -= basic arr[j] = temp basic = basic / 2 return arr# 合并def merge(left, right): result = [] while left and right: result.append(left.pop(0) if left[0] &lt;= right[0] else right.pop(0)) while left: result.append(left.pop(0)) while right: result.append(right.pop(0)) return resultdef mergeSort(arr): if len(arr) &lt;= 1: return arr mid_index = len(arr) / 2 left = mergeSort(arr[:mid_index]) right = mergeSort(arr[min_index:]) return merge(left, right) 参考： 数据结构与算法-排序篇-Python描述 排序算法(wiki)]]></content>
  </entry>
  <entry>
    <title><![CDATA[牛顿迭代法计算平方根(Golang,Python实现)]]></title>
    <url>%2F2018%2F02%2F06%2F%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95%E8%AE%A1%E7%AE%97%E5%B9%B3%E6%96%B9%E6%A0%B9-Golang-Python%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[题目： 牛顿法是通过选择一个初始点 z 然后重复这一过程求 Sqrt(x) 的近似值： 为了做到这个，只需要重复计算 10 次，并且观察不同的值（1，2，3，……）是如何逐步逼近结果的。 然后，修改循环条件，使得当值停止改变（或改变非常小）的时候退出循环。 牛顿迭代法的原理很简单，其实是根据f(x)在x0附近的值和斜率，估计f(x)和x轴的交点，看此动态图： 提示：定义并初始化一个浮点值，向其提供一个浮点语法或使用转换： 12z := float64(1)z := 1.0 Golang实现12345678910111213141516171819202122232425262728293031package mainimport ( "fmt" "math")func Sqrt(x float64) float64 &#123; // 根据提示 定义一个初始值 来套用公式 z := 1.00 // 临时变量 记录z 上次的值 temp := 0.00 for &#123; // 计算出最新的z值 z = z - (z*z-x)/(2*z) fmt.Println(z) if math.Abs(z-temp) &lt; 0.000000000000001 &#123; // 当值停止改变（或改变非常小）的时候退出循环 break &#125; else &#123; // 赋值最后的值 temp = z &#125; &#125; return z&#125;func main() &#123; fmt.Println("牛顿法：", Sqrt(2)) fmt.Println("math.Sqrt(２):", math.Sqrt(2))&#125; Python实现 one: 12345678910import mathdef func(a): if a &lt; 1e-6: return 0 last = a c = a / 2 while math.fabs(c-last) &gt; 1e-6: last = c c = (c + a / 2) / 2 return c two: 123456c = 2err = 1e-15t = cwhile abs(t - c/t)&gt;err: t = (c/t+t)/2.0print(t) 参考链接： 牛顿法计算平方根-Python Go指南练习之《循环和函数》(Loops and Functions) 练习：循环和函数 牛顿迭代法计算平方根(Java,Python实现) 求牛顿开方法的算法及其原理，此算法能开任意次方吗?]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用Python操作redis方法总结]]></title>
    <url>%2F2018%2F01%2F29%2F%E4%BD%BF%E7%94%A8Python%E6%93%8D%E4%BD%9Credis%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[分布式爬虫使用的是Scrapy+Redis的架构，使用Python操作的redis的方法，总结一下。Python操作redis redis模块提供两个类Redis和StrictRedis用于实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令，Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py（官方建议使用StrictRedis）。 示例代码如下： 12345678910$ pip install redis使用redis：&gt;&gt;&gt; import redis&gt;&gt;&gt; pool = redis.ConnectionPool(host='localhost', port=6379, decode_responses=True) &gt;&gt;&gt; r = redis.Redis(connection_pool=pool)使用StrictRedis&gt;&gt;&gt; pool = redis.ConnectionPool(host='127.0.0.1', port=6379)&gt;&gt;&gt; r = redis.StrictRedis(connection_pool=pool) Python操作redis集群 操作redis集群，无法使用redis模块进行操作，需使用redis-py-cluster操作 示例代码： 12345678910$ pip install redis-py-cluster&gt;&gt;&gt; from rediscluster import StrictRedisCluster&gt;&gt;&gt; # Requires at least one node for cluster discovery. Multiple nodes is recommended.&gt;&gt;&gt; startup_nodes = [&#123;"host": "127.0.0.1", "port": "7000"&#125;]&gt;&gt;&gt; rc = StrictRedisCluster(startup_nodes=startup_nodes, decode_responses=True)&gt;&gt;&gt; rc.set("foo", "bar")True&gt;&gt;&gt; print(rc.get("foo"))'bar' 参考链接： 使用redis-py的两个类Redis和StrictRedis时遇到的坑 redis-py-cluster]]></content>
  </entry>
  <entry>
    <title><![CDATA[python实现10个随机整数序列几种方法]]></title>
    <url>%2F2018%2F01%2F18%2Fpython%E5%AE%9E%E7%8E%B010%E4%B8%AA%E9%9A%8F%E6%9C%BA%E6%95%B4%E6%95%B0%E5%BA%8F%E5%88%97%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[numpy模块：numpy.random.randint(low[, high, size]) 返回随机的整数，位于半开区间 [low, high)。 12import numpy as nprelist = np.random.randint(10,size=10) numpy模块：numpy.random.permutation(x)返回随机序列 12import numpy as nprelist = list(np.random.permutation(10)) 使用random返回随机序列 正常写法： 1relist = [random.randint(x, 100) for x in range(10)] 二逼写法： 1relist = list(map(lambda x: random.randint(x, 100), [x for x in range(10)]))]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos升级glibc，编译过程及问题注意]]></title>
    <url>%2F2018%2F01%2F12%2Fcentos%E5%8D%87%E7%BA%A7glibc%EF%BC%8C%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%E5%8F%8A%E9%97%AE%E9%A2%98%E6%B3%A8%E6%84%8F%2F</url>
    <content type="text"><![CDATA[centos升级glibc2.14，编译过程及问题注意买了一台小鸡搭ss，因为是openvz的机器，无法安装kvm的加速，于是装了个OpenVZ改google bbr的加速。因为glibc版本过低，无法安装，于是升级，此为前提。特别注意： 请勿在生产环境或者没有备份数据的情况下升级glibc 使用源代码方式升级 Glibc 是需要小心考虑的事情，因为整个系统几乎所有应用程序都依赖于原有的动态库，升级的时候，执行”make install”命令会打断旧的动态库链接，改为指向新的库文件。在这个过程中，不同的链接指向新旧不同版本的库文件，很容易导致系统崩溃，崩溃后，一般是无法重新启动的。 安装glibc过程： 查看系统glibc库版本可使用如下命令: 1$ strings /lib64/libc.so.6 |grep GLIBC_ 点击下载glibc2.14, 然后编辑安装: 12345$ tar -xzvf glibc-2.14.tar.gz &amp;&amp; cd glibc-2.14$ mkdir build // 在glibc-2.14目录下建立build文件夹$ cd build // 进入build目录$ ../configure --prefix=/opt/glibc-2.14 // 配置glibc并设置当前glibc-2.14安装目录$ make &amp;&amp; make install // 编译安装glibc-2.14库 建立glibc软链 12$ rm -rf /lib64/libc.so.6 // 先删除先前的libc.so.6软链$ ln -s /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6 Note： 删除libc.so.6之后可能导致系统命令不可用的情况, 可使用如下方法解决: 1$ LD_PRELOAD=/opt/glibc-2.14/lib/libc-2.14.so ln -s /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6 如果上述更新失败可使用如下命令还原: 1$ LD_PRELOAD=/lib64/libc-2.12.so ln -s /lib64/libc-2.12.so /lib64/libc.so.6 // libc-2.12.so 此项是系统升级前的版本 编译过程可能会出现：Can’t open configuration file /opt/glibc-2.14/etc/ld.so.conf: No such file or directory，如下解决: 12345缺少了必要的编译文件ld.so.conf。通过find命令找到对应的文件位置。$ find / -name &quot;ld.so.conf&quot; /etc/ld.so.conf$ cp /etc/ld.so.conf /opt/glibc-2.14/etc/$ make install 参考链接： 分享Centos6.5升级glibc过程 解决’GLIBC_2.14’ not found问题时遇到的坑 使用源代码将 Glibc 升级到 2.6]]></content>
  </entry>
  <entry>
    <title><![CDATA[2017年终总结]]></title>
    <url>%2F2017%2F12%2F31%2F2017%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[关于工作 工作依然在努力。 2017年是来到上海的第二个年头，不知不觉一年就过去。今年换了一份新工作，总算是脱离之前不清不楚的工作范围。现在的工作是Python开发+运维。 刚毕业的时候做简单的helpdesk的时候，也没想到能走到今天写代码的这一步。当积累了知识越多，就会发现缺少的知识更多。特别是IT这个行业，更需要持续不断的学习。 大专毕业5年，一路走来，每个阶段都是自己独自度过，颇为坎坷。明年会往后端方向努力，争取能做个后端开发，或者运维开发一类的工作，希望这能成为以后长期发展的方向。 关于生活 生活并非一成不变。 年纪在一点点变大，父母在一点点变老。虽然每年都会有点积蓄，但是离让自己有资本追求远方，或者让父母不在那么苟且，仍是杯水车薪。工资比刚毕业了涨了点，但是花钱却越来越节省，越来越感觉到：有钱真是能为所欲为。 今年的冬天格外寒冷。关于教育，关于所谓的清理外来(DiDuan)人口，真的是让人觉得：没钱，真是活着都会非常吃力，时时刻刻都能感受这个社会给你的种种压力。而且随着年龄的增加，这种压力会愈来愈大。 依旧单身，目前来看无改变这种状态可能。 关于未来 未来谁知道呢。 这个世界对普通人，是很公平的。你付出多少，积累多少，你就能得到多少。 行路难，行路难，多歧路，今安在。长风破浪会有时，直挂云帆济沧海。 2017-12-31]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mac 10.12报错:Click More Info… to visit the Java Developer Kit download website.解决方法]]></title>
    <url>%2F2017%2F12%2F20%2FMac-10-12%E6%8A%A5%E9%94%99-Click-More-Info%E2%80%A6-to-visit-the-Java-Developer-Kit-download-website-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[今天学习java，用vim写的正爽呢，弹窗报错如下图。根据报错升级了java，还是不行。上网查询，解决之. 解决方法： 安装提示点击“More Info”先升级java版本 第一步安装的jre，如果你需要编译java，那么还需要升级jdk 安装完成jre，jdk问题就解决了]]></content>
  </entry>
  <entry>
    <title><![CDATA[升级vmware14，Not enough physical memory报错解决方法]]></title>
    <url>%2F2017%2F12%2F15%2F%E5%8D%87%E7%BA%A7vmware14%EF%BC%8CNot-enough-physical-memory%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[使用debian，一时手贱update了下系统，vmware虚拟机无法使用,升级vmware版本，仍报错‘Not enough physical memory’， 求助google，解决。 大概原因是vmware有个限制的physical memory的设定，不让intel的显卡开启3d加速一类的功能，解除这个限制，更新了就ok了，命令如下： 1234567891011sudo sucd /tmp cp /usr/lib/vmware/modules/source/vmmon.tar .tar xf vmmon.tar rm vmmon.tar wget https://raw.githubusercontent.com/mkubecek/vmware-host-modules/fadedd9c8a4dd23f74da2b448572df95666dfe12/vmmon-only/linux/hostif.c mv -f hostif.c vmmon-only/linux/hostif.c tar cf vmmon.tar vmmon-only rm -fr vmmon-only mv -f vmmon.tar /usr/lib/vmware/modules/source/vmmon.tar ./vmware-modconfig --console --install-all 参考链接：not-enough-physical-memory-is-available-to-power-on-this-virtual-machine-vmware]]></content>
  </entry>
  <entry>
    <title><![CDATA[常见爬虫反爬策略的处理办法及个人一些感悟]]></title>
    <url>%2F2017%2F12%2F12%2F%E5%B8%B8%E8%A7%81%E7%88%AC%E8%99%AB%E5%8F%8D%E7%88%AC%E7%AD%96%E7%95%A5%E7%9A%84%E5%A4%84%E7%90%86%E5%8A%9E%E6%B3%95%E5%8F%8A%E4%B8%AA%E4%BA%BA%E4%B8%80%E4%BA%9B%E6%84%9F%E6%82%9F%2F</url>
    <content type="text"><![CDATA[今年一年都是在与爬虫打交道，国内常见的电商平台都已经抓了遍，有些小体量的平台貌似也没放过。目前一共处理了30多个电商平台的数据抓取，一些反爬策略的体验及处理。 平台目前遇到的反爬策略以下几种，比较常见： HTTP请求头限制（最简单，基础） IP地址限制 IP+Cookie限制 用户行为分析限制 请求URL加时间戳salt，sign验证（最难处理） 数据蜜罐 对应的处理方法 请求头限制：但凡是写过爬虫的，都会自己定义个header，这个最简单不过了，最好是定义一个随机的user-agent，然后定义一个中间件，随机取。 IP地址限制：这个反爬最常用，最好的的处理方法就是自建一个ASDL拨号的代理池，使用民用的ASDL账号，隔段时间重新拨号，不容易被ban。如果是使用网上抓来的一些代理ip，估计都是被轮了无数遍，效果可能并不会很理想。 IP+Cookie限制：目前几个大的电商平台都是使用这种方式来限制。taobao+tmall+amazon都是这种，淘宝，Amazon还好一点，使用较稳定的代理ip，速度慢一点，数据还是能保证的。tmall就不行了，一个ip地址请求几次，就强制让你登陆，这种就需要带Cookie登陆了。 用户行为分析限制：这个好像是刚兴起的反爬策略，估计是和大数据相关的分析策略。淘宝目前的月销量 就是使用这种反爬。这种只能尽可能的模拟用户真实行为，或者有大量稳定的代理ip，切换速度要快，要不然还真没啥好的处理办法。 请求URL加时间戳salt，sign验证：这种反爬策略一般就是一些小平台，没有web端站点，只有移动端APP，通过抓包能获取到json的url。比如贝店这个平台，就是这种。这个url就会带着时间戳的salt+sign。目前我并没有好的处理方法，分析不出来对方使用的加密方式，无从下手，只能在url失效之前，重新抓包，跑下数据。 数据蜜罐：这种使用的，就我目前抓取的这些平台，使用的并不多。可能Amazon，ebay一些页面使用这个手段，没有具体测试。如果碰到了，就要具体分析是哪个数据出了问题，尽量不去获取这个数据，或者尽量pass这个页面。 一些感悟 反反爬就那几种策略，但是反爬限制却是越来越高级，现在就可以分析用户行为，或许可能过不几年就用AI来反爬也说不定，毕竟魔高一尺道高一丈。 爬虫偶尔写写可以，专职爬虫并不那么美好。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ELK时间问题总结]]></title>
    <url>%2F2017%2F12%2F11%2FELK%E6%97%B6%E9%97%B4%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[使用分布式爬虫抓取的报错log，需要拿来分析，降低平台抓取错误率。使用FELK（Filebeat+ElastiSearch+Logstash+Kibana）框架。碰到的时间相关问题总结一下。 logstash写入es时间为获取日志时间，非日志打印时间 解决方法：使用target替换当前写入Es的timestamp（若需要kibana的时间range功能，此字段必须保留） 123456date &#123; match =&gt; [&quot;logdate(自己定义的logtime)&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;] target =&gt; &quot;@timestamp&quot; &quot;locale&quot; =&gt; &quot;en&quot; timezone =&gt; &quot;UTC&quot;&#125; Es时间准确，kibana显示相差8个小时 解决方法：修改kibana时区设置 kibana-Visualize按照固定间隔生成图表 操作方法：]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ansible Playbook执行多个tasks配置分析]]></title>
    <url>%2F2017%2F10%2F25%2FAnsible-Playbook%E6%89%A7%E8%A1%8C%E5%A4%9A%E4%B8%AAtasks%E9%85%8D%E7%BD%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[分布式爬虫需要多机器配置，又懒得每台机器都去登录配置环境，于是用了Ansible，相当方便。关于一个playbook配置执行多个tasks，分享一波。 网上充斥各种教程，都是让你这么来执行多个tasks：task list中的各任务按次序逐个在hosts中指定的所有主机上执行即在所有主机上完成第一个任务后再开始第二个。在运行自下而下某playbook时如果中途发生错误所有已执行任务都将回滚因此在更正playbook后重新执行一次即可。 123456tasks: - name: echo date command: echo &quot;date&quot;tasks: - name: echo date_output command: echo &quot;date_output&quot; 然而并不能按照上面的说法来依次执行，这种写法只会报个WARNING，然后只执行最后一个tasks： 1[WARNING]: While constructing a mapping from /opt/ansible/test.yaml, line 1, column 2, found a duplicate dict key (tasks). Using last defined value only. playbook在同一个指定操作的远程主机并不能顺序执行多个tasks。正确的写法，应该是把命令全部写在一个tasks里，like this： 12345tasks: - name: echo date command: echo &quot;date&quot; - name: echo date_output command: echo &quot;date_output&quot; 在多个指定操作的远程主机可以顺序执行多个tasks： 123456789- hosts: webservers #指定操作的远程主机 tasks: - name: echo date command: echo &quot;date&quot; - hosts: dbservers #另一组远程主机 tasks: - name: echo date_output command: echo &quot;date_output&quot; 参考链接： ansible小结（八）ansible-playbook简单使用 Ansible 进阶技巧 Ansible–playbook基础]]></content>
  </entry>
  <entry>
    <title><![CDATA[Debian/Ubuntu无netstat命令解决方案]]></title>
    <url>%2F2017%2F10%2F15%2FDebian-Ubuntu%E6%97%A0netstat%E5%91%BD%E4%BB%A4%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[之前用的ubuntu系统，不知道是系统不稳定，还是我操作有问题。经常无缘无故的崩溃，选择许久，换成了Debian系统。相当稳定，流畅。 Debian系统默认不带netstat等命令，如果使用就会报错 1bash: netstat: command not found - Debian/Ubuntu Linux 解决方法： 1234sudo apt-get install net-tools#如果需要ping的话，安装如下软件sudo apt-get install iputils-ping net-tools包含arp, ifconfig, netstat, rarp, nameif and route命令，如果使用这些命令报错，可以尝试安装。 参考链接：bash: netstat: command not found - Debian/Ubuntu Linux]]></content>
  </entry>
  <entry>
    <title><![CDATA[计算机科学和PYTHON编程导论 Lecture 10]]></title>
    <url>%2F2017%2F10%2F12%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%92%8CPYTHON%E7%BC%96%E7%A8%8B%E5%AF%BC%E8%AE%BA-Lecture-10%2F</url>
    <content type="text"><![CDATA[选择排序12345678910111213141516#!/usr/bin/env python# coding: utf-8# author: nemo_chendef selSort(L): for i in range(len(L) - 1): minIndx = i minVal = L[i] j = i + 1 while j &lt; len(L): if minVal &gt; L[j]: minIndx = j minVal = L[j] j += 1 temp = L[i] L[i] = L[minIndx] L[minIndx] = temp 合并排序1234567891011121314151617181920212223242526272829#!/usr/bin/env python# coding: utf-8# author: nemo_chenimport operatordef merge(left, right, compare): result = [] i, j = 0, 0 while i &lt; len(left) and j &lt; len(right): if compare(left[i], right[j]): return.append(left[i]) i += 1 else: result.append(right[j]) j += 1 while (i &lt; len(left)): result.append(left[i]) i += 1 while (j &lt; len(right)): result.append(right[j]): j += 1 return resultdef mergeSort(L, compare=operator.lt): if len(L) &lt; 2: result L[:] else: middle = int(len(L)/2) left = mergeSort(L[:middle], compare) right = mergeSort(l[middle], compare) return merge(left, right, compare)]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用ElasticDump迁移数据，报错trying to auto create mapping, but dynamic mapping is disabled 个人解决方法]]></title>
    <url>%2F2017%2F10%2F11%2F%E4%BD%BF%E7%94%A8ElasticDump%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%8A%A5%E9%94%99trying-to-auto-create-mapping-but-dynamic-mapping-is-disabled-%E4%B8%AA%E4%BA%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[近日公司老机房网络一直异常，于是和运维确认迁移服务到新机房。Es服务内有将近1Y的数据量，使用ElasticDump迁移数据。 报错trying to auto create mapping, but dynamic mapping is disabled. 解决方法： 若使用动态mapping，可在新建index时，修改mapping属性为”index.mapper.dynamic”:true，(index.mapper.dynamic这个是动态索引开关，如果关闭，那么你新写入一个索引或者存在的一个索引新增一个字段，你又没提前定义好mapping，那么这次写入将会被拒绝)。 若不想使用动态mapping，可按照原来index属性新建，特别注意的是请勿迁移之前，手动用其它方法在新建的index导入任何数据，否则会报错trying to auto create mapping, but dynamic mapping is disabled。 参考链接： ElasticSearch使用ElasticDump迁移数据报错，已解决报错，仍其他问题帮忙看看。]]></content>
  </entry>
  <entry>
    <title><![CDATA[json因BOM报错(No JSON object could be decoded)解决办法]]></title>
    <url>%2F2017%2F09%2F28%2Fjson%E5%9B%A0BOM%E6%8A%A5%E9%94%99-No-JSON-object-could-be-decoded-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Requests抓取网页Json数据报错“No JSON object could be decoded”，一顿分析，发现是网页上json格式有问题，是带BOM的UTF-8 解决办法就是删除字段前面的bom字符，代码如下：1info = json.loads(requests.get(url).text.encode('utf-8')[3:].decode('utf-8') 参考链接： JSON 入门指南 【已解决】Python中解析Json文件出错：ValueError : No JSON object could be decoded –&gt; Python中Json库不支持带BOM的UTF-8 json带bom头如何处理 Unexpected UTF-8 BOM (decode using utf-8-sig)]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python之禅]]></title>
    <url>%2F2017%2F09%2F24%2FPython%E4%B9%8B%E7%A6%85%2F</url>
    <content type="text"><![CDATA[希望以后自己能写出像“Python之禅”所说的那种Python代码。123456789101112131415161718192021&gt;&gt;&gt; import thisThe Zen of Python, by Tim PetersBeautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren&apos;t special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one-- and preferably only one --obvious way to do it.Although that way may not be obvious at first unless you&apos;re Dutch.Now is better than never.Although never is often better than *right* now.If the implementation is hard to explain, it&apos;s a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea -- let&apos;s do more of those! 12345678910111213141516优美胜于丑陋。显式胜于隐式。简单胜于复杂。复杂胜于难懂。扁平胜于嵌套。稀疏胜于紧密。可读性应当被重视。尽管实用性会打败纯粹性，特例也不能凌驾于规则之上。不要忽略任何错误，除非你确认要这么做。面对不明确的定义，拒绝猜测的诱惑。找到一种最好唯一的一种方法去解决问题。虽然一开始这种方法并不是显而易见，因为你不是 Python 之父。做好过不做，但没有思考的做还不如不做。如果实现很难说明，那它是个坏想法。如果实现容易解释，那它有可能是个好想法。命名空间是个绝妙的想法，请多加利用。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Centos自动安装Python2.7脚本]]></title>
    <url>%2F2017%2F09%2F20%2FCentos%E8%87%AA%E5%8A%A8%E5%AE%89%E8%A3%85Python2-7%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[机房迁移，分布式爬虫服务需要重新部署 Centos默认Python版本为Python2.6，需升级为Python2.7 自动Shell脚本安装，代码如下，供参考： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/bin/bash#author: nemo_chenecho "Start update development tools"sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.reposudo yum makecachesudo yum updatesudo yum groupinstall -y 'development tools'sudo yum install -y zlib-devel bzip2-devel openssl-devel xz-libs wgetsudo yum install -y vimecho "Development complate!"echo "Start install Python2.7"cd /optwget -c http://mirrors.sohu.com/python/2.7.10/Python-2.7.10.tar.xz &amp;&amp; tar xvf Python-2.7.10.tar.xzcd Python-2.7.10 &amp;&amp; ./configure --prefix=/usr/local/make &amp;&amp; sudo make altinstallsudo rm /usr/bin/pythonsudo ln -s /usr/local/bin/python2.7 /usr/bin/pythonsudo cp /usr/lib64/python2.6/lib-dynload/_sqlite3.so /usr/local/lib/python2.7/sqlite3/echo "Python2.7 install complate!"echo "Pip start install!"curl https://bootstrap.pypa.io/get-pip.py | sudo python -mkdir ~/.pipcat&gt;~/.pip/pip.conf&lt;&lt;EOF[global]index-url = https://pypi.douban.com/simpleEOFsudo /usr/local/bin/pip install virtualenv -i https://pypi.douban.com/simpleecho "Pip install complate!"sudo cp /usr/lib64/python2.6/lib-dynload/_sqlite3.so /usr/local/lib/python2.7/sqlite3/ sudo sed -i '1s/python/python2.6/g' /usr/bin/yumecho "Python2.7 install ok!!!!!!"]]></content>
  </entry>
  <entry>
    <title><![CDATA[Scrapy请求URL，302异常个人解决(user-agent方面)]]></title>
    <url>%2F2017%2F08%2F18%2FScrapy%E8%AF%B7%E6%B1%82URL%EF%BC%8C302%E5%BC%82%E5%B8%B8%E4%B8%AA%E4%BA%BA%E8%A7%A3%E5%86%B3-user-agent%E6%96%B9%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[使用Scrapy请求url，未发现因为cookie，或者请求频率导致的302，具体分析，是由于请求的随机user-agent里面有mobile的ua。删除mobile的ua，请求正常 更新最新pc端ua，再次请求，无异常 2017最新Ua-List（pc端）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# encoding=utf-8&quot;&quot;&quot; User-Agents &quot;&quot;&quot;agents = [ &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/603.2.4 (KHTML, like Gecko) Version/10.1.1 Safari/603.2.4&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.79 Safari/537.36 Edge/14.14393&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.109 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/603.2.5 (KHTML, like Gecko) Version/10.1.1 Safari/603.2.5&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063&quot;, &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.3; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot;, &quot;Mozilla/5.0 (iPad; CPU OS 10_3_2 like Mac OS X) AppleWebKit/603.2.4 (KHTML, like Gecko) Version/10.0 Mobile/14F89 Safari/602.1&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.109 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.109 Safari/537.36&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/10.1 Safari/603.1.30&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.86 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 5.1; rv:52.0) Gecko/20100101 Firefox/52.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.109 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.86 Safari/537.36&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/58.0.3029.110 Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/603.2.5 (KHTML, like Gecko) Version/10.1.1 Safari/603.2.5&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64; rv:45.0) Gecko/20100101 Firefox/45.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.86 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.86 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.86 Safari/537.36 OPR/46.0.2597.32&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/59.0.3071.109 Chrome/59.0.3071.109 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:53.0) Gecko/20100101 Firefox/53.0&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 OPR/45.0.2552.898&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36 OPR/46.0.2597.39&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:54.0) Gecko/20100101 Firefox/54.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.7&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/602.4.8 (KHTML, like Gecko) Version/10.0.3 Safari/602.4.8&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; Touch; rv:11.0) like Gecko&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; rv:52.0) Gecko/20100101 Firefox/52.0&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36&quot;,] Downlink：点击这里]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用ruby连接Cassandra报错（Timed out）解决方法]]></title>
    <url>%2F2017%2F08%2F15%2F%E4%BD%BF%E7%94%A8ruby%E8%BF%9E%E6%8E%A5Cassandra%E6%8A%A5%E9%94%99%EF%BC%88Timed-out%EF%BC%89%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[公司es搜索使用源数据存储在Cassandra数据库，今天接到需求，需要查询每个id总数量 有个ruby在跑Cassandra数据，懒得改成python，直接用ruby写，结果查询报错:1234/home/ops/.rvm/gems/ruby-1.9.3-p551/gems/cassandra-driver-3.1.0/lib/cassandra/future.rb:631:in `get&apos;: Timed out (Cassandra::Errors::TimeoutError)from cassandra-driver-3.1.0/lib/cassandra/future.rb:396:in `get&apos;from /home/ops/.rvm/gems/ruby-1.9.3-p551/gems/cassandra-driver-3.1.0/lib/cassandra/session.rb:123:in `execute&apos;from ./validate.rb:30:in `&lt;main&gt;&apos; 解决方法如下： 1session.execute("select count(*) FROM keyspacename.tabname WHERE source='keyword'", timeout:100) 如果是在cqlsh里面报错timeout，可使用： 1cqlsh --request-timeout 120 host 参考链接: Ruby Driver for Apache Cassandra Operation Time Out Error in cqlsh console of cassandra]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java判断某年某月多少天]]></title>
    <url>%2F2017%2F08%2F08%2FJava%E5%88%A4%E6%96%AD%E6%9F%90%E5%B9%B4%E6%9F%90%E6%9C%88%E5%A4%9A%E5%B0%91%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[初学Java,写个demo 123456789101112131415161718192021222324252627282930313233343536373839404142434445/************************************************************************* &gt; File Name: year_to_days.java &gt; Author: nemo_chen &gt; Created Time: Tue Aug 8 23:29:27 2017 ************************************************************************/import java.util.*;public class year_to_days &#123; public static void main(String[] args)&#123; int days = 0; //user input Scanner sc = new Scanner(System.in); System.out.print(&quot;Please input yeads: &quot;); int year = sc.nextInt(); System.out.print(&quot;Please input mount: &quot;); int month = sc.nextInt(); switch(month)&#123; case 1: case 3: case 5: case 7: case 8: case 10: case 12: days=31; break; case 4: case 6: case 9: case 11: days=30; break; case 2: //判断闰年 if(year%4==0 &amp;&amp; year%100!=0 || year%400==0) days=29; else days=28; break; default: System.out.println(&quot;month input error!&quot;); System.exit(0); &#125; System.out.printf(&quot;天数：%d\n&quot;, days); &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python中执行JS命令]]></title>
    <url>%2F2017%2F08%2F02%2FPython%E4%B8%AD%E6%89%A7%E8%A1%8CJS%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[自动将Javascipt代码翻译成Python代码 支持全部ECMA Scipt 5.1 可使用pyimport语法从Javascript代码中导入Python库 解释速度快，可作为独立的JS解释器 友好的JS执行方式，js2py.eval_js Installation1$ sudo pip install js2py Simple Example1234567891011&gt;&gt;&gt; import js2py&gt;&gt;&gt; js2py.eval_js(&apos;console.log(&quot;Hello World!&quot;)&apos;)&apos;Hello World!&apos;&gt;&gt;&gt; add = js2py.eval_js(&apos;function add(a,b)&#123;return a+b&#125;&apos;)&gt;&gt;&gt; add&apos;function add(a, b) &#123; [python code] &#125;&apos;&gt;&gt;&gt; add(1,2) + 3&gt;&gt;&gt; add.constructor&apos;function Function() &#123; [python code] &#125;&apos;&gt;&gt;&gt; js2py.eval_js(&quot;Object.prototype.toString.call(Function(&apos;s&apos;, &apos;return s+arguments[1]&apos;)(new Date(), 7).__proto__)&quot;)&apos;[object String]&apos; More advanced usage example1234567891011121314151617181920212223242526# Adding Python built-in sum to the JS context:&gt;&gt;&gt; context = js2py.EvalJs(&#123;&apos;python_sum&apos;: sum&#125;) &gt;&gt;&gt; js_code = &apos;&apos;&apos;var a = 10function f(x) &#123;return x*x&#125;&apos;&apos;&apos;&gt;&gt;&gt; context.execute(js_code)# Get value of variable a:&gt;&gt;&gt; context.a10# context.f behaves just like js function so you can supply more than 1 argument. &apos;9&apos;*&apos;9&apos; in javascript is 81.&gt;&gt;&gt; context.f(&apos;9&apos;, 0) 81 # context.f has all attributes of normal JavaScript object&gt;&gt;&gt; context.f.toString()u&apos;function f(x) &#123; [python code] &#125;&apos;&gt;&gt;&gt; context.f.bindfunction bind(thisArg) &#123; [python code] &#125;# You can also add variables to the context:&gt;&gt;&gt; context.foo = [1,2,3] # context.foo is now Js Array object and behaves just like javascript array!&gt;&gt;&gt; context.foo.push(4) 4&gt;&gt;&gt; context.foo.to_list() # convert to python list[1, 2, 3, 4]# You can use Python objects that you put inside the context!&gt;&gt;&gt; context.eval(&apos;python_sum(new Array(1, 2, 3))&apos;) Note 忽视了”strict mode” 不支持with语法 eval的非直接调用会被当做直接调用 Other Examples In Js2Py all JavaScript objects are a subclass of PyJs object. For example JS Number is represented by PyJsNumber class. js2py.eval_js and js2py.EvalJs automatically tries to convert PyJs type to builtin python type. So for example if you execute: 1&gt;&gt;&gt; js2py.eval_js(&apos;var a = &quot;hello&quot;; a&apos;) eval_js will return unicode type (u”hello”). However for complex types such conversion is impossible and JsObjectWrapper is returned. See the conversion table JsType -&gt; PyType: 123456&gt;&gt;&gt; Boolean -&gt; bool&gt;&gt;&gt; String -&gt; unicode (str in Python 3)&gt;&gt;&gt; Number -&gt; float (or int/long if whole number)&gt;&gt;&gt; undefined -&gt; None&gt;&gt;&gt; null -&gt; None&gt;&gt;&gt; OTHER -&gt; JsObjectWrapper JsObjectWrapper supports: getitem, getattr, setitem, setattr, repr and call. Moreover it has to_list and to_dict methods if you want to convert it to builtin python type. 123456789101112131415&gt;&gt;&gt; js = js2py.eval_js(&apos;d = &#123;a:1, b:2&#125;&apos;)&gt;&gt;&gt; js&#123;a: 1, b: 2&#125; &gt;&gt;&gt; type(js)&lt;class &apos;js2py.base.JsObjectWrapper&apos;&gt;&gt;&gt;&gt; js.a&gt;&gt;&gt; 1&gt;&gt;&gt; js[&apos;a&apos;]&gt;&gt;&gt; 1&gt;&gt;&gt; js.b = 20&gt;&gt;&gt; js&#123;a: 1, b: 20&#125; &gt;&gt;&gt; js[&apos;c&apos;] = 30&gt;&gt;&gt; js.to_dict()&#123;u&apos;a&apos;: 1, &apos;c&apos;: 30, u&apos;b&apos;: 20&#125; Also, of course you can use Js2Py to parse (tree is the same as in esprima.js) and translate JavaScript Parsing12&gt;&gt;&gt; js2py.parse_js(&apos;var $ = 5&apos;) &#123;&apos;body&apos;: [&#123;&apos;kind&apos;: &apos;var&apos;, &apos;declarations&apos;: [&#123;&apos;init&apos;: &#123;&apos;raw&apos;: None, &apos;type&apos;: u&apos;Literal&apos;, &apos;value&apos;: 5.0&#125;, &apos;type&apos;: u&apos;VariableDeclarator&apos;, &apos;id&apos;: &#123;&apos;type&apos;: u&apos;Identifier&apos;, &apos;name&apos;: u&apos;$&apos;&#125;&#125;], &apos;type&apos;: u&apos;VariableDeclaration&apos;&#125;], &apos;type&apos;: u&apos;Program&apos;&#125; Translating12345678910111213141516171819202122&gt;&gt;&gt; print js2py.translate_js(&apos;var $ = 5&apos;)import js2py.pyjs, sysfor m in sys.modules.keys(): if m.startswith(&apos;js2py&apos;): del sys.modules[m]del js2py.pyjsdel js2pyfrom js2py.pyjs import *# setting scopevar = Scope( JS_BUILTINS )set_global_object(var)# Code follows:var.registers([u&apos;$&apos;])var.put(u&apos;$&apos;, Js(5.0))pyimport statementFinally, Js2Py also supports importing any Python code from JavaScript using ‘pyimport’ statement:&gt;&gt;&gt; x = &quot;&quot;&quot;pyimport urllib; var result = urllib.urlopen(&apos;https://www.google.com/&apos;).read(); console.log(result.length) &quot;&quot;&quot;&gt;&gt;&gt; js2py.eval_js(x)18211 原文链接]]></content>
  </entry>
  <entry>
    <title><![CDATA[计算机科学和PYTHON编程导论 Week Three ClassCode & ClassWork]]></title>
    <url>%2F2017%2F07%2F17%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%92%8CPYTHON%E7%BC%96%E7%A8%8B%E5%AF%BC%E8%AE%BA-Week-Three-ClassCode-ClassWork%2F</url>
    <content type="text"><![CDATA[ClassCode 递归 1234567891011121314151617181920#!/usr/bin/env python# coding: utf-8# author: nemo_chen# 递归def iterMul(a, b): result = 0 while b &gt; 0: result += a b -= 1 return resultdef recurMul(a, b): if b == 1: return a else: return a + recurMul(a, b-1)def factR(n): if n == 1: return n else: return n * factR(n-1) 汉塔塔 123456789101112#!/usr/bin/env python# coding: utf-8# author: nemo_chendef printMove(fr, to): print(&apos;Move from &apos; + str(fr) + &apos; to &apos; + str(to))def Towers(n ,fr, to, spare): if n == 1: printMove(fr, to) else: Towers(n-1, fr, spare, to) Towers(n, fr, to, spare) Towers(n-1, spare, to, fr) 斐波那契 123456789#!/usr/bin/env python# coding: utf-8# author: nemo_chendef fib(x): assert type(x) == int and x &gt;= 0 if x == 0 or x == 1: return 1 else: return fib(x-1) + fib(x-2)]]></content>
  </entry>
  <entry>
    <title><![CDATA[Windows域环境通过组策略推送补丁脚本]]></title>
    <url>%2F2017%2F07%2F02%2FWindows%E5%9F%9F%E7%8E%AF%E5%A2%83%E9%80%9A%E8%BF%87%E7%BB%84%E7%AD%96%E7%95%A5%E6%8E%A8%E9%80%81%E8%A1%A5%E4%B8%81%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Windows域环境通过组策略推送补丁脚本 将下载好的MSU文件提取到一个共享路径，如\s1\app。 新建一个txt文件，对每一个安装补丁添加一行下面的命令，最后保存，修改文件后缀名为bat，也将其放置到共享路径。示例如下：1Wusa.exe &lt;WSU文件共享路径&gt; /quiet 新建一个GPO，导航到计算机配置\策略\Windows设置\脚本（启动/关机），双击右侧的“启动”，点击添加该bat脚本的网络路径。 将GPO链接到能包含目标计算机的容器后，重启需要打补丁的计算机。 参考链接：组策略推送补丁]]></content>
  </entry>
  <entry>
    <title><![CDATA[Github 访问时出现Permission denied (public key)]]></title>
    <url>%2F2017%2F06%2F28%2FGithub-%E8%AE%BF%E9%97%AE%E6%97%B6%E5%87%BA%E7%8E%B0Permission-denied-public-key%2F</url>
    <content type="text"><![CDATA[使用git clone命令时出现Permission denied (public key) 。解决方法： ssh-add ~/.ssh/id_rsa ssh-add -l查看是否添加成功 若报错（Could not open a connection to your authentication agent），执行 1eval \`ssh-agent\` 重复上述命令]]></content>
  </entry>
  <entry>
    <title><![CDATA[深究递归和迭代的区别、联系、优缺点及实例对比]]></title>
    <url>%2F2017%2F06%2F24%2F%E6%B7%B1%E7%A9%B6%E9%80%92%E5%BD%92%E5%92%8C%E8%BF%AD%E4%BB%A3%E7%9A%84%E5%8C%BA%E5%88%AB%E3%80%81%E8%81%94%E7%B3%BB%E3%80%81%E4%BC%98%E7%BC%BA%E7%82%B9%E5%8F%8A%E5%AE%9E%E4%BE%8B%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[概念区分 递归的基本概念:程序调用自身的编程技巧称为递归,是函数自己调用自己.一个函数在其定义中直接或间接调用自身的一种方法,它通常把一个大型的复杂的问题转化为一个与原问题相似的规模较小的问题来解决,可以极大的减少代码量.递归的能力在于用有限的语句来定义对象的无限集合. 使用递归要注意的有两点: 递归就是在过程或函数里面调用自身; 在使用递归时,必须有一个明确的递归结束条件,称为递归出口. 递归分为两个阶段: 递推:把复杂的问题的求解推到比原问题简单一些的问题的求解; 回归:当获得最简单的情况后,逐步返回,依次得到复杂的解.利用递归可以解决很多问题:如背包问题,汉诺塔问题,…等.斐波那契数列为:0,1,1,2,3,5…由于递归引起一系列的函数调用,并且有可能会有一系列的重复计算,递归算法的执行效率相对较低. 迭代:利用变量的原值推算出变量的一个新值.如果递归是自己调用自己的话,迭代就是A不停的调用B. 辩证看递归和迭代 所谓递归，简而言之就是应用程序自身调用自身，以实现层次数据结构的查询和访问。递归的使用可以使代码更简洁清晰，可读性更好（对于初学者到不见得），但由于递归需要系统堆栈，所以空间消耗要比非递归代码要大很多，而且，如果递归深度太大，可能系统资源会不够用。 往往有这样的观点：能不用递归就不用递归，递归都可以用迭代来代替。 诚然，在理论上，递归和迭代在时间复杂度方面是等价的（在不考虑函数调用开销和函数调用产生的堆栈开销），但实际上递归确实效率比迭代低，既然这样，递归没有任何优势，那么是不是就，没有使用递归的必要了，那递归的存在有何意义呢？万物的存在是需要时间的检验的，递归没有被历史所埋没，即有存在的理由。从理论上说，所有的递归函数都可以转换为迭代函数，反之亦然，然而代价通常都是比较高的。但从算法结构来说，递归声明的结构并不总能够转换为迭代结构，原因在于结构的引申本身属于递归的概念，用迭代的方法在设计初期根本无法实现，这就像动多态的东西并不总是可以用静多态的方法实现一样。这也是为什么在结构设计时，通常采用递归的方式而不是采用迭代的方式的原因，一个极典型的例子类似于链表，使用递归定义及其简单，但对于内存定义(数组方式)其定义及调用处理说明就变得很晦涩，尤其是在遇到环链、图、网格等问题时，使用迭代方式从描述到实现上都变得不现实。因而可以从实际上说，所有的迭代可以转换为递归，但递归不一定可以转换为迭代。 采用递归算法需要的前提条件是，当且仅当一个存在预期的收敛时，才可采用递归算法，否则，就不能使用递归算法。 递归其实是方便了程序员难为了机器，递归可以通过数学公式很方便的转换为程序。其优点就是易理解，容易编程。但递归是用栈机制实现的，每深入一层，都要占去一块栈数据区域，对嵌套层数深的一些算法，递归会力不从心，空间上会以内存崩溃而告终，而且递归也带来了大量的函数调用，这也有许多额外的时间开销。所以在深度大时，它的时空性就不好了。 而迭代虽然效率高，运行时间只因循环次数增加而增加，没什么额外开销，空间上也没有什么增加，但缺点就是不容易理解，编写复杂问题时困难。 定义 优点 缺点 迭代：利用变量的原值推算出变量的一个新值，迭代就是A不停的调用B. 1）迭代效率高，运行时间只因循环次数增加而增加；2）没什么额外开销，空间上也没有什么增加； 1） 不容易理解；2） 代码不如递归简洁；3） 编写复杂问题时困难。 递归：程序调用自身的编程技巧称为递归 1）大问题化为小问题,可以极大的减少代码量；2）用有限的语句来定义对象的无限集合.；3）代码更简洁清晰，可读性更好 1）递归调用函数,浪费空间；2）递归太深容易造成堆栈的溢出； 实例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt; using namespace std; //迭代实现斐波那契数列 long fab_iteration(int index) &#123; if(index == 1 || index == 2) &#123; return 1; &#125; else &#123; long f1 = 1L; long f2 = 1L; long f3 = 0; for(int i = 0; i &lt; index-2; i++) &#123; f3 = f1 + f2; //利用变量的原值推算出变量的一个新值 f1 = f2; f2 = f3; &#125; return f3; &#125; &#125; //递归实现斐波那契数列 long fab_recursion(int index) &#123; if(index == 1 || index == 2) &#123; return 1; &#125; else &#123; return fab_recursion(index-1)+fab_recursion(index-2); //递归求值 &#125; &#125; int main(int argc, char* argv[]) &#123; cout &lt;&lt; fab_recursion(10) &lt;&lt; endl; cout &lt;&lt; fab_iteration(10) &lt;&lt; endl; return 0; &#125; 因而，“能不用递归就不用递归，递归都可以用迭代来代替”这样的理解，还是辩证的来看待，不可一棍子打死。*/1,2部分摘自网络，略有改动，向原作者致敬！ 原文链接]]></content>
  </entry>
  <entry>
    <title><![CDATA[Cassandra COPY 命令的用法]]></title>
    <url>%2F2017%2F05%2F25%2FCassandra-COPY-%E5%91%BD%E4%BB%A4%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Cassandra COPY 命令简单用法: Cassandra提供了COPY命令,可将数据库里面的table导入或者导出到本地,实现简单数据迁移 导出到本地: 1COPY keyspace_name.table_name (id,lastname) TO &apos;../testname.csv&apos; WITH HEADER = TRUE ; 从本地导入: 1COPY keyspace_name.table_name (id,firstname) FROM &apos;../testnem.csv&apos; WITH HEADER = TRUE ; Note:NOTE: table_name后面若不跟key,默认导出全部数据.特别注意的是,若需导入的表格超过300w的数据,不建议使用COPY命令导入,可使用Cassandra提供的工具sstableloader导入,也可使用其提供的API导入 参考链接： Cassandra COPY用法 Cassandra sstableloader用法]]></content>
  </entry>
  <entry>
    <title><![CDATA[python ahocorasick 从本地文件读取文本，进行关键字匹配]]></title>
    <url>%2F2017%2F05%2F25%2Fpython-ahocorasick-%E4%BB%8E%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%EF%BC%8C%E8%BF%9B%E8%A1%8C%E5%85%B3%E9%94%AE%E5%AD%97%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[需求 使用Python+pyahocorasick，匹配关键字，关键字大概在10-20个汉字之间。 构建ahocorasick的文本，是从本地文件key_word的读入。格式如下： Keyword Keyword 母婴专区&lt;辅食&lt;面仔/面条:婴幼儿,幼儿,婴儿,儿童,宝宝 面条,细面,粗面,手工面,蔬菜面,营养面,碎面,挂面,面仔 参考代码如下：123456789101112131415161718192021222324252627282930import ahocorasickA = ahocorasick.Automaton()titles = [&apos;Hello Kitty3色蔬菜细面300克 婴儿幼儿营养面条宝宝辅食面条&apos;]word_dict = &#123;&#125;with open(&apos;categories.csv&apos;, &apos;r&apos;) as f: for line in f.readlines(): line = line.strip() word_key = line.split(&apos;:&apos;)[0] word_value = list(line.split(&apos;:&apos;)[1].split(&apos;|&apos;)) word_dict[word_key] = word_value line = (line.split(&apos;:&apos;)[1].split(&apos;|&apos;)) for word in line: if word == &quot;&quot;: continue A.add_word(word, word)A.make_automaton()for title in titles: category = [] aa = A.iter(title) ret = [] matches = &#123;&#125; for (k,v) in aa: matches[v] = 1 for (k,v) in matches.items(): ret.append(k) for value in word_dict.items(): if ret[0] in value[1]: category.append(value[0]) #关键字太多，所以写死了一个keyword匹配的结果 #print(ret[0], value[0], value[1]) print(category[0])]]></content>
  </entry>
  <entry>
    <title><![CDATA[Fuck,一个神奇的纠错工具]]></title>
    <url>%2F2017%2F05%2F05%2FFuck-%E4%B8%80%E4%B8%AA%E7%A5%9E%E5%A5%87%E7%9A%84%E7%BA%A0%E9%94%99%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[thefuck是一个使用Python编写的开源小工具，它可以自动纠正前一个命令的拼写错误。这个工具非常酷，尤其对于常常使用命令行的童鞋 thefuck支持Mac OS X和Linux系统。 安装步骤： ubuntu 12sudo apt install python3-dev python3-pip pip3 install --user thefuck (or sudo -H pip3 install thefuck) macOs 1brew install thefuck 用法： 先alias一个别名，别名随便 123vim .vimrc or .bashrceval &quot;$(thefuck --alias fuck)&quot;source ~/.vimrc or ~/.bashrc 示例： 12345678 ➜ puthonNo command &apos;puthon&apos; found, did you mean: Command &apos;python&apos; from package &apos;python-minimal&apos; (main) Command &apos;python&apos; from package &apos;python3&apos; (main)zsh: command not found: puthon➜ fuckpython [enter/↑/↓/ctrl+c]Python 3.4.2 (default, Oct 8 2014, 13:08:17) Git地址更多用法请参考README]]></content>
  </entry>
  <entry>
    <title><![CDATA[cassandra CQL 常用操作]]></title>
    <url>%2F2017%2F04%2F20%2Fcassandra-CQL-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[CQL客户端链接bin/cqlsh ip username password 常用操作命令 建立keyspace语句，keyspace类似于 mysql 中的数据库，一个数据库中可以有很多表； 1CREATE KEYSPACE mykeyspace WITH REPLICATION = &#123; &apos;class&apos; : &apos;SimpleStrategy&apos;,&apos;replication_factor&apos; : 2 &#125; ，replication_factor 表示 数据被复制几份 建表语句： 12CREATE TABLE task ( row_split text, column_split text, username text, parent_user text, priority int, url text, status int, is_dir boolean, channel_code text, is_multilayer boolean, action_type int, create_time bigint, finish_time bigint, id text, subtask_result text, reason text, retry_time int, PRIMARY KEY (row_split, column_split) ) ; primary key 的第一个元素是rowkey，第二个元素的是cluster key； 建索引语句： 1create index task_status on task(status); cassandra的索引不支持范围查找，类似于 位图索引 或者 哈希索引，支持 ＝ 操作，不支持&lt; 或 &gt; 之类的范围查找； 查询语句: 12select * from task where status=2;注意，cassandra where 子句里面的，除了rowkey以外，其他字段如果要使用 = 操作，必须建立二级索引，而且cassandra里面的二级索引 不支持范围查询，类似于位图索引，不同于 BTREE索引； 删除语句: 12345单独删除某个column 或者 某行；delete column1，column2 from table where rowkey = &apos;xxxx&apos;ordelete column1，column2 from table where rowkey in (&apos;x&apos;,&apos;xx&apos;,&apos;xxx&apos;...)其中where子句是不能省略的。 删除表中的所有数据 12如果要想实现 类似 mysql中 delete from table的效果，可以使用truncate；truncate table]]></content>
  </entry>
  <entry>
    <title><![CDATA[基础 Ruby 中 Include, Extend, Load, Require 的使用区别]]></title>
    <url>%2F2017%2F04%2F15%2F%E5%9F%BA%E7%A1%80-Ruby-%E4%B8%AD-Include-Extend-Load-Require-%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Include 如下例当你Include一个模块到某个类时, 相当于把模块中定义的方法插入到类中。它允许使用 mixin。它用来 DRY 你的代码, 避免重复。例如, 当你有多个类时, 需要相同的函数时, 可以把函数定义到module中, 进行include。 下例假设模块Log和类TestClass在相同的.rb文件。如果它们存在于多个文件, 则需要使用 load 或 require 导入文件。1234567891011module Log def class_type "This class is of type: #&#123;self.class&#125;" endendclass TestClass include Log endtc = TestClass.new.class_typeputs tc #This class is of type: TestClassExtend 当你使用Extend来替换 Include 的时候, 你会添加模块里的方法为类方法, 而不是实例方法。详细请看例子： 1234567891011module Log def class_type "This class is of type: #&#123;self.class&#125;" endendclass TestClass extend Log # ...endtc = TestClass.class_typeputs tc # This class is of type: TestClass 当你在类中使用 Extend 来代替 Include, 如果你实例化 TestClass 并调用 class_type方法时，你将会得到 NoMethodError。再一次强调, 使用 Extend 时方法是类方法。 Require Require 方法允许你载入一个库并且会阻止你加载多次。当你使用 require 重复加载同一个library时，require方法 将会返回 false。当你要载入的库在不同的文件时才能使用 require 方法。下例将演示 require 的使用方式。文件 test_library.rb 和 test_require.rb 在同一个目录下。 123456789101112# test_library.rbputs " load this libary "# test_require.rbputs (require './test_library')puts (require './test_library')puts (require './test_library')# 结果为# load this libary # true# false# false Load Load 方法基本和 require 方法功能一致，但它不会跟踪要导入的库是否已被加载。因此当重复使用 load 方法时，也会载入多次。大部分情况你都会使用 require 来代替 load。但当你需要每次都要加载时候你才会使用 load, 例如模块的状态会频繁地变化, 你会使用 load 进行加载，获取最新的状态。12345678910puts load "./test_library.rb" #在这里不能省略 .rb, require可以省略puts load "./test_library.rb" puts load "./test_library.rb" #结果# load this libary#true# load this libary#true# load this libary#true]]></content>
  </entry>
  <entry>
    <title><![CDATA[git pull强制覆盖本地修改]]></title>
    <url>%2F2017%2F04%2F11%2Fgit-pull%E5%BC%BA%E5%88%B6%E8%A6%86%E7%9B%96%E6%9C%AC%E5%9C%B0%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[有时候本地的仓库出问题,需要强制pull远程仓库的代码,命令如下: 清除本地修改 1git reset --hard pull仓库代码 1git pull]]></content>
  </entry>
  <entry>
    <title><![CDATA[ruby中gsub的用法]]></title>
    <url>%2F2017%2F04%2F10%2Fruby%E4%B8%ADgsub%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[新公司的爬虫后续处理脚本都是用ruby写的,没办法又开始学习ruby,今天碰到一个gsub和gsub!的问题.如下解释: ruby中带“!”和不带”!”的方法的最大的区别就是带”!”的会改变调用对象本身了。比方说str.gsub(/a/, ‘b’)，不会改变str本身，只会返回一个新的str。而str.gsub!(/a/, ‘b’)就会把str本身给改了。 但是gsub和gsub!还有另外一个不同点就是，gsub不管怎么样都会返回一个新的字符串，而gsub!只有在有字符被替换的情况下才会返回一个新的字符串，假如说没有任何字符被替换，gsub!只会返回nil. 123456789example:[ruby] view plain copy- 'abc'.gsub(/a/, 'b') #返回'bbc'[ruby] view plain copy- 'abc'.gsub!(/a/, 'b') #返回'bbc'[ruby] view plain copy- 'abc'.gsub(/d/,'a') #返回'abc'[ruby] view plain copy- 'abc'.gsub!(/d/, 'a') #返回nil]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL查询出错提示 --secure-file-priv解决方法]]></title>
    <url>%2F2017%2F04%2F02%2FMySQL%E6%9F%A5%E8%AF%A2%E5%87%BA%E9%94%99%E6%8F%90%E7%A4%BA-secure-file-priv%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在某台DB上准备运行一个SQL语句，就是用SELECT INTO OUTFILE把查询结果写入到文件的时候提示以下信息：bash The MySQL server is running with the --secure-file-priv option so it cannot execute this statement 出现这个问题的原因是因为启动MySQL的时候使用了–secure-file-priv这个参数，这个参数的主要目的就是限制LOAD DATA INFILE或者SELECT INTO OUTFILE之类文件的目录位置，我们可以使用12SELECT @@global.secure_file_priv;查询到你当前设置的路径，默认应该是/var/lib/mysql-files 如果要解决这个问题，我们可以通过下面2种方式： 将你要导入或导出的文件位置指定到你设置的路径里 由于不能动态修改，我们可以修改my.cnf里关于这个选项的配置，然后重启即可。]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy 报错400 Bad Request,个人处理方法]]></title>
    <url>%2F2017%2F03%2F28%2Fscrapy-%E6%8A%A5%E9%94%99400-Bad-Request-%E4%B8%AA%E4%BA%BA%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[爬虫scrapy报错400 Bad Request,个人解决方法刚入职新公司开始写爬虫项目,刚好一个爬虫代码出问题,一直报错400,解决如下: 400的报错含义就是服务的不接受客户端的请求,可能是客户端的请求格式有问题,或者请求的header有问题. 如果是第一种有问题,请检查请求的url格式是否有问题. 如果是第二种问题,可重新测试当前网站的header,加入爬虫代码.特别要注意header里面的host与content-lengh的字段,还有user-agent. 参考:http://stackoverflow.com/questions/42248903/scrapy-post-request-not-working-400-bad-request 参考:https://segmentfault.com/q/1010000008902485]]></content>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu运行sh脚本sudo自动输入密码]]></title>
    <url>%2F2017%2F03%2F20%2Fubuntu%E8%BF%90%E8%A1%8Csh%E8%84%9A%E6%9C%ACsudo%E8%87%AA%E5%8A%A8%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[ubuntu运行sh脚本sudo自动输入密码以前写的一个自动清理指定磁盘文件的脚本忽然挂了,查看log发现如下报错1sudo: no tty present and no askpass program specified 根据报错,大概推断是shell交互出现问题,google之,找到问题所在:sudo 版本升级,需要增加-S参数. 使用Man查询sudo -S参数 Write the prompt to the standard error and read the password from the standard input instead of using the terminal device. The password must be followed by a newline character. 可见加上-S参数sudo才会从标准输入中读取密码，不加-S参数以上命令将起不到作用 12341 cd /opt/hlistenexp_data2 sudo -S find . -atime +7 -exec rm -f &#123;&#125; \; &lt;&lt;EOF3 PassWord4 EOF]]></content>
  </entry>
  <entry>
    <title><![CDATA[flask使用Mysql报错"ImportError: No module named MySQLdb"]]></title>
    <url>%2F2017%2F02%2F16%2Fflask-%E4%BD%BF%E7%94%A8Mysql%E6%8A%A5%E9%94%99-ImportError-No-module-named-MySQLdb%2F</url>
    <content type="text"><![CDATA[今天自己尝试写Flask代码,使用Mysql数据库,初始化时候报错ImportError: No module named MySQLdb.google之,解决方法如下: 如果没有安装python-mysql支持库,请安装12python2: pip install python-mysqldbpython3: pip install pymysql 更改原教程mysql链接如下:1SQLALCHEMY_DATABASE_URI = &apos;mysql+pymysql://.....&apos; 报错解决参考:stackoverflowflask+mysql配置参考:flask+mysql]]></content>
  </entry>
  <entry>
    <title><![CDATA[python web 部署：nginx + gunicorn + supervisor + flask 部署笔记]]></title>
    <url>%2F2017%2F02%2F08%2Fpython-web-%E9%83%A8%E7%BD%B2%EF%BC%9Anginx-gunicorn-supervisor-flask-%E9%83%A8%E7%BD%B2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[python web 部署 web开发中，各种语言争奇斗艳，web的部署方面，却没有太多的方式。简单而已，大概都是 nginx 做前端代理，中间 webservice 调用程序脚本。大概方式：nginx + webservice + script。 nginx 不用多说，一个高性能的web服务器。通常用来在前端做反向代理服务器。所谓正向与反向（reverse），只是英文说法翻译。代理服务，简而言之，一个请求经过代理服务器从局域网发出，然后到达互联网上服务器，这个过程的代理为正向代理。如果一个请求，从互联网过来，先进入代理服务器，再由代理服务器转发给局域网的目标服务器，这个时候，代理服务器为反向代理（相对正向而言）。 正向代理：{ 客户端 —》 代理服务器 } —》 服务器反向代理：客户端 —》 { 代理服务器 —》 服务器 }{} 表示局域网 nginx既可以做正向，也可以做反向。webservice 的方式同样也有很多方式。常见的有FastCGI，WSGI等。我们采用gunicorn为 wsgi容器。python为服务器script，采用flask框架。同时采用supervisor管理服务器进程。也就是最终的部署方式为：nginx + gunicorn + flask ++ supervisor 创建一个项目1mkdir myproject 创建 python 虚拟环境 virtualenv 可以说是 python 的一个大杀器。用来在一个系统中创建不同的 python 隔离环境。相互之间还不会影响，使用简单到令人发指。1234mkdir myprojectcd myprojectvirtualenv venvsource venv/bin/activate(激活虚拟环境) 安装 python web 框架 —flask flask 是一个 python web micro framework。简洁高效，使用也很简单。flask 依赖两个库 werkzeug 和 jinjia2。采用 pip 方式安装即可。 1pip install flask 测试我们的 flask 安装是否成功，并使用 flask 写一个简单的 web 服务。 vim app.py 12345678from flask import Flaskapp = Flask(__name__)@app.route('/')def index(): return 'hello world'if __name__ == '__main__': app.debug = True app.run() 启动web服务 1python app.py 此时，用浏览器访问 http://127.0.0.1:5000 就能看到网页显示 hello world。 使用 gunicorn 部署 python web 现在我们使用 flask 自带的服务器，完成了 web 服务的启动。生产环境下，flask 自带的 服务器，无法满足性能要求。我们这里采用 gunicorn 做 wsgi容器，用来部署 python。 安装 gunicorn 1pip install gunicorn 当我们安装好 gunicorn 之后，需要用 gunicorn 启动 flask，注意 flask 里面的name里面的代码启动了 app.run(),这个含义是用 flask 自带的服务器启动 app。这里我们使用了 gunicorn，myapp.py 就等同于一个库文件，被 gunicorn 调用。 1gunicron -w4 -b0.0.0.0:8000 app:app 此时，我们需要用 8000 的端口进行访问，原先的5000并没有启用。其中 gunicorn 的部署中，，-w 表示开启多少个 worker，-b 表示 gunicorn 开发的访问地址。 想要结束 gunicorn 只需执行 pkill gunicorn，有时候还的 ps 找到 pid 进程号才能 kill。可是这对于一个开发来说，太过于繁琐，因此出现了另外一个神器—supervisor，一个专门用来管理进程的工具，还可以管理系统的工具进程。 安装 supervisor123pip install supervisorecho_supervisord_conf &gt; supervisor.conf # 生成 supervisor 默认配置文件vim supervisor.conf # 修改 supervisor 配置文件，添加gunicorn 进程管理 在myapp supervisor.conf 配置文件底部添加 123456789[program:myapp]command=/home/rsj217/rsj217/myproject/venv/bin/gunicorn -w4 -b0.0.0.0:8000 myapp:app ; supervisor启动命令directory=/home/rsj217/rsj217/myproject ;项目的文件夹路径startsecs=0 ; 启动时间stopwaitsecs=0 ; 终止等待时间autostart=false ; 是否自动启动autorestart=false ; 是否自动重启stdout_logfile=/home/userpath/log/gunicorn.log ; log 日志stderr_logfile=/home/userpath/myproject/log/gunicorn.err supervisor的基本使用命令 12345678910111213141516171819supervisord-csupervisor.conf通过配置文件启动supervisorsupervisorctl-csupervisor.confstatus 察看supervisor的状态supervisorctl -c supervisor.conf reload 重新载入配置文件supervisorctl -c supervisor.conf start [all]|[appname] 启动指定/所有supervisor管理的程序进程supervisorctl -c supervisor.conf stop [all]|[appname] 关闭指定/所有supervisor管理的程序进程 安装配置 nginx 采用 apt-get方式安装最简单。运行 sudo apt-get install nginx。安装好的nginx的二进制文件放在 /usr/sbin/文件夹下面。而nginx的配置文件放在 /etc/nginx下面。 使用 supervisor 来管理 nginx。这里需要注意一个问题，linux的权限问题。nginx是sudo的方式安装，启动的适合也是 root用户，那么我们现在也需要用 root用户启动supervisor。增加下面的配置文件 12345678[program:nginx]command=/usr/sbin/nginxstartsecs=0stopwaitsecs=0autostart=falseautorestart=falsestdout_logfile=/home/userpath/myproject/og/nginx.logstderr_logfile=/home/userpath/myproject/log/nginx.err 到此为止，web 部属已经全部完成项目源码： https://github.com/lovebaicai/openvideo (包含配置文件)PS: 本来是自己的项目部署,打算自己写的.但是发现了一篇很详细的文章,就直接转过来了.原文请点击这里 ubuntu环境下配置参考这里 supervisor配置参考这里 gunicorn配置参考这里]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python+Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown进行图片缩放]]></title>
    <url>%2F2017%2F02%2F07%2FMarkDown-%E8%BF%9B%E8%A1%8C%E5%9B%BE%E7%89%87%E7%BC%A9%E6%94%BE%2F</url>
    <content type="text"><![CDATA[MarkDown进行图片缩放使用markdown编写说明文档,无奈图片有点大,google之,找到图片处理方法 直接设置图片大小,简单粗暴123![设置图片宽度高度](http://image-path.png =300x200)![设置图片宽度](http://image-path.png =300x)![设置图片高度](http://image-path.png =x200) 如果使用的是七牛的图床,可以调用七牛的API处理图片.1234567设置图片宽度高度: http://image-path.png?imageView/3/w/445/h/325imageView2/&lt;mode&gt;/w/&lt;LongEdge&gt; /h/&lt;ShortEdge&gt; /format/&lt;Format&gt; /interlace/&lt;Interlace&gt; /q/&lt;Quality&gt; /ignore-error/&lt;ignoreError&gt; ps: 七牛API使用参考:七牛API 或者也可以使用html的方法缩放,加上div使图片居中.123&lt;div align=center&gt;&lt;img src="http://image-path.png" width="400" height="400" alt="image"/&gt;&lt;/div&gt;]]></content>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 批量删除相同前缀的表]]></title>
    <url>%2F2017%2F02%2F06%2FMysql-%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E7%9B%B8%E5%90%8C%E5%89%8D%E7%BC%80%E7%9A%84%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[Mysql批量删除相同前缀的表每日需要Cron跑一下爬虫脚本,生成当日数据.今天发现累计了非常多的相同前缀的历史表数据,故删除之! 命令非常简单 123Select CONCAT( 'drop table ', table_name, ';' )FROM information_schema.tablesWhere table_name LIKE 'sound_201701_%'; 执行上述命令后,就显示匹配的Drop命令,如下图.直接复制执行就ok了. 如果需要批量修改表名,可以使用如下命令1234567Select CONCAT( 'ALTER TABLE ', table_name, 'RENAME TO ', table_name,';' )FROM information_schema.tablesWhere table_name LIKE 'sound_%';=&gt;ALTER TABLE sound_aaa RENAME TO sound_aaa;ALTER TABLE sound_bbb RENAME TO sound_bbb;(在编辑器中将“RENAME TO de”批量改为想设置的表前缀，再执行此SQL语句即可批量修改表名。)]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python paramiko 使用方法简介]]></title>
    <url>%2F2016%2F12%2F26%2Fpython-paramiko%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[python paramiko 主要介绍了python paramiko简介和使用方法，让你全面了解python的远程服务器连接和文件上传，ssh远程执行命令等 paramiko 遵循SSH2协议，支持以加密和认证的方式，进行远程服务器的连接，可以实现远程文件的上传，下载或通过ssh远程执行命令。 项目地址：https://github.com/paramiko/paramiko 官方文档：http://docs.paramiko.org/ 文档转载：http://www.codexiu.cn/python/blog/127/ (根据自己需要有删改) 一、安装 root@ubuntu:~/paramiko# pip install paramiko 运行脚本若报错’ValueError: Multibackend cannot be initialized with no backends. If you are seeing this error when trying to use default_backend() please try uninstalling and reinstalling cryptography’.可重新安装cryptography. 二、上传文件到远程服务器 原理：通过SFTPClient类根据SSH传输协议的sftp会话，实现远程文件上传、下载等操作。实现远程文件上传、下载。1234567891011121314151617181920212223242526任务：10. 1.101.187向10.1.101.186发送文件。10.1.101.187 目录/root/paramiko 有三个文件 paramikosend.py test test.tar10.1.101.186 目录/root/paramiko 开始为空文件夹执行python paramikosend.py,代码如下root@ubuntu:~/paramiko# cat paramikosend.pyimport paramiko,datetime,oshostname = '10.1.101.186'username = 'root'password = '123456'port = 22local_dir = '/root/paramiko'remote_dir = '/root/paramiko'try: t=paramiko.Transport((hostname,port)) t.connect(username=username,password=password) sftp = paramiko.SFTPClient.from_transport(t) files = os.listdir(local_dir) for f in files: sftp.put(os.path.join(local_dir,f),os.path.join(remote_dir,f)) t.close()except Exception: print "connect error!" 三、从远程服务器下载文件 原理：通过SFTPClient类根据SSH传输协议的sftp会话，实现远程文件上传、下载等操作。实现远程文件上传、下载。12345678910111213141516171819202122任务：现在10.1.101.186的/root/paramiko/temp186目录有两个文件,将其下载到10.1.101.187的/root/paramiko/temp187目录。执行 python paramikoget.py ，代码如下:root@ubuntu:~/paramiko# cat paramikoget.pyimport paramiko,datetime,oshostname = '10.1.101.186'username = 'root'password = '123456'port = 22local_dir = '/root/paramiko/temp187'remote_dir = '/root/paramiko/temp186'try: t=paramiko.Transport((hostname,port)) t.connect(username=username,password=password) sftp = paramiko.SFTPClient.from_transport(t) files = sftp.listdir(remote_dir) #这里需要注意，列出远程文件必须使用sftp，而不能用os for f in files: sftp.get(os.path.join(remote_dir,f),os.path.join(local_dir,f)) t.close()except Exception: print "connect error!" 四、执行命令测试 原理：通过SSHClient类执行命令。SSHClient类是SSH服务会话的高级表示，封装了传输、通道以及SFTPClient的校验、建立方法，通常用于执行命令。12345678910111213141516171819202122232425262728293031323334任务：通过10.1.101.187连接到10.1.101.186，然后进入目录/root/paramiko，创建一个目录lxy。执行python paramikocommand.py，代码如下：root@ubuntu:~/paramiko# cat paramikocommand.py#!/usr/bin/pythonimport paramikohostname = '10.1.101.186'username = 'root'password = '123456'port = 22ssh = paramiko.SSHClient()ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())ssh.connect(hostname=hostname,port=port,username=username,password=password)stdin, stdout, stderr = ssh.exec_command("cd /root/paramiko;mkdir lxy")print stdout.readlines()ssh.close()Note: 命令中也可以带参数：#!/usr/bin/pythonimport paramikohostname = '10.1.101.186'username = 'root'password = '123456'port = 22name='testcmd'ssh = paramiko.SSHClient()ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())ssh.connect(hostname=hostname,port=port,username=username,password=password)stdin, stdout, stderr = ssh.exec_command("cd /root/paramiko;mkdir %s" %name)print stdout.readlines()ssh.close() 五、python远程执行操作的其他开源模块 fabric:fabric是封装了paramiko模块来实现ssh来传输文件的。 pexpect:也可以实现ssh 登录到某个用户指定的主机上，运行某个用户指定的命令 六、与输入的CMD命令进行交互 stdin.write部分是用于交互情况下，通过该命令可以执行交互。注意这里可能会引起歧义，这里的交互并不是ssh连接过程中出现的让输入yes的交互，因为paramiko模块在连接过程中会自动处理好yes确认。这里的交互是指后面的cmd需要的执行的程序可能出现交互的情况下，可以通过该参数进行交互。123456789101112131415161718192021222324252627282930313233代码如下:stdin.write("Y\n") #简单交互，输入 'Y'使用示例:#!/usr/bin/env pythonimport sysimport paramikodef sshclient(ip, username, password, cmd): myclient = paramiko.SSHClient() myclient.set_missing_host_key_policy(paramiko.AutoAddPolicy()) myclient.connect(ip, port=22, username=username, password=password, timeout=5) stdin, stdout, stderr = myclient.exec_command(cmd) stdin.write("y\n") print stdout.readlines() myclient.close()if len(str(sys.argv[1])) &lt;= 14: cmd = 'cd /test &amp;&amp; python3 upload.py -f %s ' % sys.argv[1]else: cmd = 'cd /test &amp;&amp; python3 upload_by_id.py -f %s' % sys.argv[1]sshclient('hostname', 'username', 'password', cmd=cmd)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 发送邮件报错'Name or service not known'解决方法]]></title>
    <url>%2F2016%2F12%2F21%2FPython-%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E6%8A%A5%E9%94%99Name-or-service-not-known%2F</url>
    <content type="text"><![CDATA[前两天设置的自动发送邮件的脚本,今天未发送.查看报错如下123456789File "/usr/lib/python2.7/smtplib.py", line 256, in __init__ (code, msg) = self.connect(host, port) File "/usr/lib/python2.7/smtplib.py", line 316, in connect self.sock = self._get_socket(host, port, self.timeout) File "/usr/lib/python2.7/smtplib.py", line 291, in _get_socket return socket.create_connection((host, port), timeout) File "/usr/lib/python2.7/socket.py", line 553, in create_connection for res in getaddrinfo(host, port, 0, SOCK_STREAM):socket.gaierror: [Errno -2] Name or service not known google之,发现是连接sock端口连接失败,由于我用的是ubuntu的测试机,测试网络ok,就可能是防火墙的问题.关闭防火墙进行测试,发送ok.1ubuntu关闭防火墙命令:ufw disable]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Python自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL正则表达式匹配]]></title>
    <url>%2F2016%2F12%2F20%2FMySQL%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[概述 正则表达式和MySQL有何关系？正则表达式的作用是匹配文本，将一个模式(正则表达式)与一个文本串进行比较。MySQL用where子句对正则表达式提供了初步的支持，允许你指定正则表达式，过滤select检索出的数据。 表达式语法,基本字符匹配,基本语法如下所示：123456select prod_name from products where prod_name regexp &apos;1000&apos;上面的语句作用是检索列prod_name中包含文本1000的所有行。select prod_name from products where prod_name regexp &apos;.000&apos;上面的语句中的.是正则表达式语言中一个特殊的字符。它表示匹配任意一个字符，因此，1000和2000都匹配且返回。 PS：MySQL中的正则表达式匹配不区分大小写。为区分大小写，可使用BINARY关键字，如： 1234567891011121314151617181920212223where prod_name regexp binary &apos;jetpack .000&apos;进行OR匹配为搜索两个串之一，使用|，如下所示：select prod_name from products where prod_name regexp &apos;1000|2000|3000&apos;匹配几个字符之一匹配任何单一字符。但是，如果你只想匹配特定的字符，怎么办？可通过指定一组[和]括起来的字符完成，如下所示：select prod_name from products where prod_name regexp &apos;[123] Ton&apos;匹配范围集合可用来定义要匹配的一个或多个字符。例如，下面的集合将匹配数字0到9：[0123456789]为了简化这种类型的集合，可使用-来定义一个范围。下面的式子功能等同于上述数字列表：[0-9]范围不限于完整的集合，[1-3]和[6-9]也是合法的范围。此外，范围不一定只是数值的，[a-z]匹配任意字母字符。匹配特殊字符为了匹配特殊字符，必须用\\为前导。\\-表示查找-，\\.表示查找.。这种处理就是所谓的转义，正则表达式内具有特殊意义的所有字符都必须以这种方式转义。这包括.、|、[]、\等。匹配字符类存在找出你自己使用的数字、所有字母字符或所有数字字母字符等匹配。为了更方便的工作，可以使用预定义的字符集，称为字符类。表列出了字符类以及他们的含义： 类 说明 [:alnum:] 任意字母和数字（同[a-zA-Z0-9]） [:alnum:] 任意字母和数字（同[a-zA-Z0-9]） [:alpha:] 任意字符 [:blank:] 空格和制表 [:cntrl:] ASCII控制字符 [:digit:] 任意数字（同[0-9]） [:print:] 任意可打印字符 [:graph:] 与[:print:]相同，但不包括空格 [:lower:] 任意小写字母（同[a - z]） [:punct:] 既不在[:alnum:]又不在[:cntrl:]中任意字符 [:space:] 包括空格在内的任意空白字符 [:upper:] 任意大写字母 [:xdigt:] 任意十六进制 匹配多个实例 目前为止使用的所有正则表达式都视图匹配单词出现。如果存在一个匹配，改行被检索出来，如果不存在，检索不出任何行。但是有需要对匹配的数目进行更强的控制。例如，你可能需要寻找所有的数，不管书中包含多少个字。这可以用正则的表达式重复元字符来完成。 1234567元字符 说明* 0个或多个匹配+ 一个或多个匹配? 0个或一个匹配&#123;n&#125; n个数目的匹配&#123;n,&#125; n个以上的匹配&#123;n,m&#125; n~m个数目的匹配(m不超过255) 12345678定位符目前为止的所有例子都是匹配一个串中任意位置的文本。为了匹配特定位置的文本，需要使用下面给出的定位符：元字符 说明^ 文本的开始$ 文本的结尾[[:&amp;lt:]] 词的开始[[:&gt;:]] 词的结尾 非原创,转载自这里]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用阿里云PythonSdk,调用API获取全部主机信息]]></title>
    <url>%2F2016%2F12%2F14%2F%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91PythonSdk-%E8%B0%83%E7%94%A8API%E8%8E%B7%E5%8F%96%E5%85%A8%E9%83%A8%E4%B8%BB%E6%9C%BA%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[这周有个需求,需要把阿里云上的服务器信息拉下来统计.但是阿里云的文档实在是写的太烂.无奈google+工单.处理ok!参考资料: SDK安装和示例请参考这里 API参数请参考这里 脚本参考这里,自己根据需要有删改. 使用方法:第一步，需要初始化Client1234from aliyunsdkcore import clientclt = client.AcsClient('SFAW************','Nc2nZ6dQoiqck0*************','cn-hangzhou') NOTE:DescribeInstancesRequest是调用你对应的API的模块. 第二步, 初始化request。以ECS的DescribeRegionsRequest接口为例:123456from aliyunsdkecs.request.v20140526 import DescribeInstancesRequestrequest = DescribeInstancesRequest.DescribeInstancesRequest()request.set_PageSize(Number) # 设置返回sizenumberrequest.set_PageNumber(Number) # 设置返回pagenumberrequest.set_accept_format('json') # 设置返回格式 NOTE:DescribeInstancesRequest是调用你对应的API的模块.除了DescribeInstancesRequest参数,其它参数都需要用set_xxx来设置. 第三步, 发起API调用1result = clt.do_action(request) # 默认返回第一页,10条数据,可用set调整 示例脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151#!/usr/bin/env python# coding: utf-8'''功能介绍：1、调用阿里云API，收集所有区域 ECS 信息2、将需要的数据整理、生成 Excel 文档3、关于阿里 sdk 的安装，api 的调用请参考阿里云官网4、xlsxwriter 请参考这里：http://xlsxwriter.readthedocs.org/'''import json, systry: from termcolor import colored from xlsxwriter import workbook from aliyunsdkcore import client from aliyunsdkecs.request.v20140526 import DescribeInstancesRequestexcept ImportError as e: print(colored('%s : %s' % ('Error', e), 'red')) exit(9)reload(sys)sys.setdefaultencoding('utf8')def get_sys_info(key, secret, zone, page): ''' 1、获取该区域全部主机详细信息 2、参数：cn-qingdao、cn-hangzhou、cn-beijing 等 ''' # 与阿里云建立有效连接 clt = client.AcsClient(key, secret, zone) # 获取该区域全部实例详细信息 request = DescribeInstancesRequest.DescribeInstancesRequest() request.set_PageSize(100) request.set_PageNumber(page) # 将数据格式化成 json，默认为 XML request.set_accept_format('json') # 发起请求，获取数据 result = json.loads(clt.do_action(request)).get('Instances').get('Instance') return resultdef format_data(data_info): ''' 从全部数据中整理出需要的数据 ''' result = [] for line in data_info: data = ( line.get('InstanceId'), line.get('ZoneId'), line.get('HostName'), line.get('InstanceName'), line.get('PublicIpAddress').get('IpAddress'), line.get('InnerIpAddress').get('IpAddress'), line.get('Cpu'), line.get('Memory'), line.get('InternetMaxBandwidthOut'), line.get('Status'), line.get('CreationTime'), line.get('ExpiredTime') ) result.append(data) return resultdef write_excel(file, data): ''' 1、设置 Excel 样式 2、将数据写入到 Excel 中 ''' # 生成 Excel 文件 work = workbook.Workbook(file) # 建立工作表，表名默认 worksheet = work.add_worksheet() # 设置字体加粗、字体大小 format_title = work.add_format(&#123;'bold': True, 'font_size': 16&#125;) # 设置水平对齐、垂直对齐 format_title.set_align('center') format_title.set_align('vcenter') format_body = work.add_format(&#123;'font_size': 14&#125;) # 设置样式，行高、列宽 worksheet.set_row(0, 25) worksheet.set_column(0, 0, 30) worksheet.set_column(1, 1, 20) worksheet.set_column(2, 3, 28) worksheet.set_column(4, 5, 25) worksheet.set_column(6, 6, 12) worksheet.set_column(7, 9, 16) worksheet.set_column(10, 11, 25) # 定义表头 title = ( '实例 ID', '所在区域', '主机名称', '主机别名', '公网地址', '私网地址', 'CPU 核数', '内存大小 MB', '网络带宽 MB', '运行状态', '创建时间', '过期时间' ) row = 0 col = 0 # 表头写入文件，引用样式 for item in title: worksheet.write(row, col, item, format_title) col += 1 # 内容写入文件，引用样式 for line in data: row += 1 col = 0 for key in line: worksheet.write(row, col, str(key), format_body) #ip地址是list类型,需转换成str. col += 1 work.close()def main(): key = 'key' secret = 'secret' zones = ['cn-qingdao', 'cn-hangzhou', 'cn-beijing', 'cn-shanghai] #根据需要修改 filename = './aliyunSystemToExcel.xlsx' result = [] for zone in zones: for page in range(1, 2): # 根据主机数量,设置page数 info = get_sys_info(key, secret, zone, page) data = format_data(info) [result.append(line) for line in data] write_excel(filename, result)if __name__ == '__main__': main()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Aliyun</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python获取Linux磁盘容量]]></title>
    <url>%2F2016%2F12%2F12%2FPython%E8%8E%B7%E5%8F%96Linux%E7%A3%81%E7%9B%98%E5%AE%B9%E9%87%8F%2F</url>
    <content type="text"><![CDATA[使用cron服务,定时跑脚本,监控磁盘容量.Python脚本监控磁盘使用量,导入Mail模块,超过定值,邮件通知(附上参考脚本) Python磁盘操作模块os.statvfs()函数 系统中的df命令应该调用了linux的函数statfs()，这里我使用python，调用的是 os.statvfs()函数。 1234567891011121314151617181920212223242526需要的头文件imprt os #os模块，statvfs函数在此模块中import statvfs #里面有相应的宏，F_BSIZE等，可以不需要。vfs=os.statvfs(“目录”)返回这个目录所在磁盘的信息。F_BSIZE = 0 # 首选block大小 Preferred file system block sizeF_FRSIZE = 1 # 基本文件block大小 Fundamental file system block sizeF_BLOCKS = 2 #文件系统block总数 Total number of file system blocks (FRSIZE)F_BFREE = 3 #空闲block数量 Total number of free blocksF_BAVAIL = 4 # 非超级用户可用的block数量 Free blocks available to non-superuserF_FILES = 5 # 总的文件节点数量 Total number of file nodesF_FFREE = 6 #空闲的文件节点的数量 Total number of free file nodesF_FAVAIL = 7 #非超级用户可用的空闲文件节点数量 Free nodes available to non-superuserF_FLAG = 8 # Flags (see your local statvfs man page)F_NAMEMAX = 9 # Maximum file name length 读取有多种方式，比如vfs[0],vfs.f_bsize,vfs[F_BSIZE]，都可以读取首选block大小的值。 计算容量就是 block大小*block数量 123456789101112131415161718192021222324#更改默认除法运算，使得除法计算得到float而不是intfrom __future__ import division#获得磁盘信息vfs=os.statvfs("目录")#1k－blocks栏，总容量KBk_blocks=vfs.f_bsize*vfs.f_blocks/1024#Used,使用量KB，总容量减去空闲容量used=vfs.f_bsize*(vfs.f_blocks-vfs.f_bfree)/1024#Available，有效容量KBavailable=vfs.f_bsize*vfs.f_bavail/1024#use%,使用量，%,round(浮点数，精确到小数点后的位数）use=round(used/(used+available)*100,2) 为什么use不是由used/k_blocks 看上去，使用量/总容量 就是使用率，但是忽略了一点 总容量=使用量+未使用量+不可使用量 所以其实重点就是在于这个不可使用量，使用率=使用量/(使用量+未使用量) 才是正确的值。 参考脚本:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/env pythonimport osdef disk_stat(): hd = &#123;&#125; disk = os.statvfs("/var/lib/test") disk1 = os.statvfs("/") disksize = disk.f_bsize * disk.f_blocks/(1024*1024*1024) used = disk.f_bsize * (disk.f_blocks - disk.f_bfree) / (1024 ** 3) hd['diskused'] = format((used / float(disksize)), '.2f') disksize1 = disk1.f_bsize * disk1.f_blocks/(1024*1024*1024) used1 = disk1.f_bsize * (disk1.f_blocks - disk1.f_bfree) / (1024 ** 3) hd['diskused1'] = format((used1 / float(disksize1)), '.2f') #return used, disksize, diskused, used1, disksize1, diskused1 return hddef Email(): import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.application import MIMEApplication import datetime user = 'test@test.com' pwd = 'test' to = ['test@test.com'] msg = MIMEMultipart() msg['Subject'] = 'disk Exceed the limit, Please Process' msg['From'] = user msg['To'] = ','.join(to) part = MIMEText('test disk Exceed the limit, Please Process') msg.attach(part) server = smtplib.SMTP('smtp.test.com') server.login(user, pwd) server.sendmail(user, to, msg.as_string()) server.close()if __name__ == '__main__': hd = disk_stat() if hd['diskused'] &gt; 0.75 or hd['diskused1'] &gt; 0.75: Email()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python自动化</tag>
        <tag>Linux</tag>
        <tag>Disk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab服务详解]]></title>
    <url>%2F2016%2F12%2F10%2Fcrontab%E6%9C%8D%E5%8A%A1%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[crontab服务详解最近需要把爬虫跑出来的数据处理成表格,然后按时发送给业务人员.但是一直有问题,于是重新温习了cron服务. 1、先来一个小小的例子12345678910111213141516171819202122232425262728293031323334353637383940[root@root test]# crontab -l查看当前用户的定时任务 也可以 crontab -uroot -l查看指定用户的定时任务。千万不要忘了中间的 sh 表示用户拿什么来执行命令00 02 * * * sh /home/admin/optbash/dailyBackup.sh00 02 * * * sh /home/admin/optbash/deleteDebugSql.sh建立一个用定时任务跑的bash脚本：[root@root test]# touch test.sh[root@root test]# vim test.sh编辑如下内容，将系统当前时间输出到 console.txt 文件然后保存，增加可执行权限/bin/echo `date` &gt; /home/admin/test/console.txt[root@root test]# lltotal 8-rw-r--r-- 1 root root 29 Mar 27 21:31 console.txt-rwxr-xr-x 1 root root 48 Mar 27 21:28 test.sh[root@root test]# chmod +x ./test.sh追加 crontab 定时任务，每分钟触发：[root@root test]# crontab -e00 02 * * * sh /home/admin/optbash/dailyBackup.sh00 02 * * * sh /home/admin/optbash/deleteDebugSql.sh* * * * * sh /home/admin/test/test.sh前面是已经存在的定时任务，后面执行test.sh脚本的是追加的 保存后提示已经装载了新的定时任务"/tmp/crontab.HauiiV" 3L, 143C writtencrontab: installing new crontab再次查看定时任务列表,可以看到定时任务已经添加[root@root test]# crontab -l00 02 * * * sh /home/admin/optbash/dailyBackup.sh00 02 * * * sh /home/admin/optbash/deleteDebugSql.sh* * * * * sh /home/admin/test/test.sh[root@root test]#查看console.txt有没有每分钟写入console.txt文件[root@root test]# vim console.txtFri Mar 27 21:40:01 EDT 2015可以看到最近一次的写入时间。 2、看看crontab 的时间表达式 基本格式 : * command 分 时 日 月 周 命令 然后来几个实际的例子：123456789101112131415161718191、每分钟执行一次* * * * *2、每隔一小时执行一次00 * * * *or* */1 * * * (/表示频率)3、每小时的15和30分各执行一次15,45 * * * * （,表示并列）4、在每天上午 8- 11时中间每小时 15 ，45分各执行一次15,45 8-11 * * * command （-表示范围）5、每个星期一的上午8点到11点的第3和第15分钟执行3,15 8-11 * * 1 command6、每隔两天的上午8点到11点的第3和第15分钟执行3,15 8-11 */2 * * command 3、其他命令介绍1234567891011121314151617名称 : crontab使用权限 : 所有使用者使用方式 :crontab file [-u user]-用指定的文件替代目前的crontab。crontab-[-u user]-用标准输入替代目前的crontab.crontab-1[user]-列出用户目前的crontab.crontab-e[user]-编辑用户目前的crontab.crontab-d[user]-删除用户目前的crontab.crontab-c dir- 指定crontab的目录。 4、crond 安装与配置服务1234567891011121314151617181920212223242526272829安装crontab：yum install crontabs服务操作说明：/sbin/service crond start //启动服务/sbin/service crond stop //关闭服务/sbin/service crond restart //重启服务/sbin/service crond reload //重新载入配置查看crontab服务状态：service crond status手动启动crontab服务：service crond start查看crontab服务是否已设置为开机启动，执行命令：ntsysv加入开机自动启动：chkconfig –level 35 crond on 5、查看报错log1234安装mail服务sudo apt-get install sendmailsudo apt-get install sendmail-cfcat /var/mail/user PS:更多内容参考这里]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中date、datetime、string的相互转换]]></title>
    <url>%2F2016%2F12%2F10%2Fpython%E4%B8%ADdate%E3%80%81datetime%E3%80%81string%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[使用python的时候,经常需要各种时间相互转换,大概简单记录下. 类型互转123456789101112131415161718192021222324252627282930313233343536373839404142434445import datetimeimport time#string转datetime&gt;&gt;&gt;str = '2016-12-05'&gt;&gt;&gt;date_time = datetime.datetime.strptime(str,'%Y-%m-%d')&gt;&gt;&gt;date_timedatetime.datetime(2016,12,05,0,0)#datetime转string&gt;&gt;&gt;date_time.strftime('%Y-%m-%d')'2016-12-05'#datetime转时间戳&gt;&gt;&gt;time_time = time.mktime(date_time.timetuple())&gt;&gt;&gt;time_time1353254400.0#时间戳转string&gt;&gt;&gt;time.strftime('%Y-%m-%d',time.localtime(time_time))'2016-12-05'#date转datetime&gt;&gt;&gt;date = datetime.date.today()&gt;&gt;&gt;date&gt;&gt;&gt;datetime.date(2016,12,05)&gt;&gt;&gt;datetime.datetime.strptime(str(date),'%Y-%m-%d') #将date转换为str，在由str转换为datetime&gt;&gt;&gt;datetime.datetime(2016,12,05,0,0) 时间加减123456789101112131415&gt;&gt;&gt; from datetime import datetime, timedelta&gt;&gt;&gt; now = datetime.now()&gt;&gt;&gt; nowdatetime.datetime(2015, 5, 18, 16, 57, 3, 540997)&gt;&gt;&gt; now + timedelta(hours=10)datetime.datetime(2015, 5, 19, 2, 57, 3, 540997)&gt;&gt;&gt; now - timedelta(days=1)datetime.datetime(2015, 5, 17, 16, 57, 3, 540997)&gt;&gt;&gt; now + timedelta(days=2, hours=12)datetime.datetime(2015, 5, 21, 4, 57, 3, 540997)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Datetime</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 连接操作各类数据库]]></title>
    <url>%2F2016%2F12%2F10%2Fpython-%E8%BF%9E%E6%8E%A5%E6%93%8D%E4%BD%9C%E5%90%84%E7%B1%BB%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[python 连接操作各类数据库摘要： 用Python写脚本也有一段时间了，经常操作数据库（MySQL），现在就整理下对各类数据库的操作，如后面有新的参数会补进来，慢慢完善。 一，python 操作 MySQL:详情见：这里 mac 安装： http://sourceforge.net/projects/mysql-python/?source=dlp sudo python setup.py build ubuntu安装: apt-get install python-mysqldb 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#!/bin/env python# -*- encoding: utf-8 -*-#-------------------------------------------------------------------------------# Purpose: example for python_to_mysql# Author: zhoujy# Created: 2013-06-14# update: 2013-06-14#-------------------------------------------------------------------------------import MySQLdbimport os#建立和数据库系统的连接，格式#conn = MySQLdb.connect(host='localhost',user='root',passwd='123456',db='test',port=3306,charset='utf8')#指定配置文件，确定目录,或则写绝对路径cwd = os.path.realpath(os.path.dirname(__file__))db_conf = os.path.join(cwd, 'db.conf')conn = MySQLdb.connect(read_default_file=db_conf,host='localhost',db='test',port=3306,charset='utf8')#要执行的sql语句query = 'select id from t1'#获取操作游标cursor = conn.cursor()#执行SQLcursor.execute(query)#获取一条记录,每条记录做为一个元组返回,返回3，游标指到第2条记录。result1 = cursor.fetchone()for i in result1: print i#返回影响的行数 print cursor.rowcount#获取指定数量记录,每条记录做为一个元组返回,返回1，2，游标从第2条记录开始，游标指到第4条记录。result2 = cursor.fetchmany(2)for i in result2: for ii in i: print ii#获取所有记录,每条记录做为一个元组返回,返回3，4，7，6,游标从第4条记录开始到最后。result3 = cursor.fetchall()for i in result3: for ii in i: print ii#获取所有记录,每条记录做为一个元组返回,返回3，4，7，6,游标从第1条记录开始#重置游标位置，0为偏移量，mode＝absolute | relative,默认为relativecursor.scroll(0,mode='absolute')result3 = cursor.fetchall()for i in result3: for ii in i: print ii#以下2种方法都可以把数据插入数据库：#(one)for i in range (10,20): query2 = 'insert into t1 values("%d",now())' %i cursor.execute(query2) #提交 conn.rollback()#(two)rows = []for i in range (10,20): rows.append(i)query2 = 'insert into t1 values("%s",now())'#executemany 2个参数,第2个参数是变量。cursor.executemany(query2,rows)#提交conn.commit()#选择数据库query3 = 'select id from dba_hospital'#重新选择数据库conn.select_db('chushihua')cursor.execute(query3)result4 = cursor.fetchall()for i in result4: for ii in i: print ii#不定义query，直接执行：cursor.execute("set session binlog_format='mixed'")#关闭游标，释放资源cursor.close()'''+------+---------------------+| id | modifyT |+------+---------------------+| 3 | 2010-01-01 00:00:00 || 1 | 2010-01-01 00:00:00 || 2 | 2010-01-01 00:00:00 || 3 | 2010-01-01 00:00:00 || 4 | 2013-06-04 17:04:54 || 7 | 2013-06-04 17:05:36 || 6 | 2013-06-04 17:05:17 |+------+---------------------+ 注意：在脚本中，密码写在脚本里面很容易暴露，这样可以用一个配置文件的方式来存密码，如db.conf：123[client]user=rootpassword=123456 二， python 操作 MongoDB:详情见这里123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#!/bin/env python# -*- encoding: utf-8 -*-#-------------------------------------------------------------------------------# Purpose: example for python_to_mongodb# Author: zhoujy# Created: 2013-06-14# update: 2013-06-14#-------------------------------------------------------------------------------import pymongoimport os#建立和数据库系统的连接,创建Connection时，指定host及port参数conn = pymongo.Connection(host='127.0.0.1',port=27017)#admin 数据库有帐号，连接-认证-切换库db_auth = conn.admindb_auth.authenticate('sa','sa')#连接数据库db = conn.abc#连接表collection = db.stu#查看全部表名称db.collection_names()#print db.collection_names()#访问表的数据，指定列item = collection.find(&#123;&#125;,&#123;"sname":1,"course":1,"_id":0&#125;)for rows in item: print rows.values()#访问表的一行数据print collection.find_one()#得到所有的列for rows in collection.find_one(): print rows#插入collection.insert(&#123;"sno":100,"sname":"jl","course":&#123;"D":80,"S":85&#125;&#125;)#或u = dict(sno=102,sname='zjjj',course=&#123;"D":80,"S":85&#125;)collection.insert(u)#得到行数print collection.find().count()print collection.find(&#123;"sno":100&#125;)#排序，按照某一列的值。pymongo.DESCENDING:倒序；pymongo.ASCENDING:升序。按照sno倒序item = collection.find().sort('sno',pymongo.DESCENDING)for rows in item: print rows.values()#多列排序item = collection.find().sort([('sno',pymongo.DESCENDING),('A',pymongo.ASCENDING)])#更新，第一个参数是条件，第二个参数是更新操作，$set,%inc,$push,$ne,$addToSet,$rename 等collection.update(&#123;"sno":100&#125;,&#123;"$set":&#123;"sno":101&#125;&#125;)#更新多行和多列collection.update(&#123;"sno":102&#125;,&#123;"$set":&#123;"sno":105,"sname":"SSSS"&#125;&#125;,multi=True)#删除，第一个参数是条件，第二个参数是删除操作。collection.remove(&#123;"sno":101&#125;)'''sno:学号；sname：姓名；course：科目db.stu.insert(&#123;"sno":1,"sname":"张三","course":&#123;"A":95,"B":90,"C":65,"D":74,"E":100&#125;&#125;)db.stu.insert(&#123;"sno":2,"sname":"李四","course":&#123;"A":90,"B":85,"X":75,"Y":64,"Z":95&#125;&#125;)db.stu.insert(&#123;"sno":3,"sname":"赵五","course":&#123;"A":70,"B":56,"F":85,"G":84,"H":80&#125;&#125;)db.stu.insert(&#123;"sno":4,"sname":"zhoujy","course":&#123;"A":64,"B":60,"C":95,"T":94,"Y":85&#125;&#125;)db.stu.insert(&#123;"sno":5,"sname":"abc","course":&#123;"A":87,"B":70,"Z":56,"G":54,"H":75&#125;&#125;)db.stu.insert(&#123;"sno":6,"sname":"杨六","course":&#123;"A":65,"U":80,"C":78,"R":75,"N":90&#125;&#125;)db.stu.insert(&#123;"sno":7,"sname":"陈二","course":&#123;"A":95,"M":68,"N":84,"S":79,"K":89&#125;&#125;)db.stu.insert(&#123;"sno":8,"sname":"zhoujj","course":&#123;"P":90,"B":77,"J":85,"K":68,"L":80&#125;&#125;)db.stu.insert(&#123;"sno":9,"sname":"ccc","course":&#123;"Q":85,"B":86,"C":90,"V":87,"U":85&#125;&#125;)'''计算Mongodb文档中各集合的数目：import pymongoconn = pymongo.Connection(host='127.0.0.1',port=27017)db = conn.abc #abc文档for tb_name in db.collection_names(): #循环出各集合名 Count = db[tb_name].count() #计算各集合的数量 if Count &gt; 2: #过滤条件 print tb_name + ':' + str(Count)'''conn = pymongo.Connection(host='127.0.0.1',port=27017)db = conn.abcfor tb_name in db.collection_names(): print tb_name + ':' exec('print ' + 'db.'+tb_name+'.count()') #变量当集合的处理方式ORconn = pymongo.Connection(host='127.0.0.1',port=27017)db = conn.abcfor tb_name in db.collection_names(): mon_dic=db.command("collStats", tb_name) #以字典形式返回 print mon_dic.get('ns'),mon_dic.get('count')''' Note: MongoDB升级到了3.0之后，用python的连接会出错：12pymongo.errors.OperationFailure: command SON([('authenticate', 1), ('user', u'dba'), ('nonce', u'8c7842b068e14d3'), ('key', u'584ec63f1cdfd8525ce33d99cd269c2c')]) failed: auth failed表示认证失败，说明MongoDB升级之后，对用用户的加密方式改变了。那就升级pymongo。 123456789101112131415161718192021222324$ sudo pip install pymongo --upgrade升级成功，要是没有安装pip，看这里：http://www.saltycrane.com/blog/2010/02/how-install-pip-ubuntu/ubuntu10.10之后：$ sudo apt-get install python-pip python-dev build-essential$ sudo pip install --upgrade pip$ sudo pip install --upgrade virtualenvubuntu10.10之前的老版本：$ sudo apt-get install python-setuptools python-dev build-essential$ sudo easy_install pip$ sudo pip install --upgrade virtualenv升级成功之后，继续执行python脚本，还是出错：AttributeError: 'module' object has no attribute 'Connection'表示没有 Connection ，pymongo升级完之后不支持了，看手册，发现用MongoClient 来替换了Connection。修改脚本：conn = pymongo.Connection(host='127.0.0.1',port=27017)改成conn = pymongo.MongoClient(host='127.0.0.1',port=27017) 最后执行python，正常。 三，python 操作 Redis:详情见这里12345678910111213141516171819202122232425262728#!/bin/env python# -*- encoding: utf-8 -*-#-------------------------------------------------------------------------------# Purpose: example for python_to_mongodb# Author: zhoujy# Created: 2013-06-14# update: 2013-06-14#-------------------------------------------------------------------------------import redisf = open('aa.txt')while True: line = f.readline().strip().split(' # ') if line == ['']: break UserName,Pwd,Email = line# print name.strip(),pwd.strip(),email.strip() rc = redis.StrictRedis(host='127.0.0.1',port=6379,db=15) rc.hset('Name:' + UserName,'Email',Email) rc.hset('Name:' + UserName,'Password',Pwd)f.close()alluser = rc.keys('*')#print alluserprint "===================================读出存进去的数据==================================="for user in alluser: print ' # '.join((user.split(':')[1],rc.hget(user,'Password'),rc.hget(user,'Email'))) 四，python 操作 memcache:详情见这里1234567891011121314151617181920212223242526272829303132333435import memcachemc = memcache.Client(['127.0.0.1:11211'],debug=1)#!/usr/bin/env python#coding=utf-8import MySQLdbimport memcacheimport sysimport timedef get_data(mysql_conn):# nn = raw_input("press string name:") mc = memcache.Client(['127.0.0.1:11211'],debug=1) t1 =time.time() value = mc.get('zhoujinyia') if value == None: t1 = time.time() print t1 query = "select company,email,sex,address from uc_user_offline where realName = 'zhoujinyia'" cursor= mysql_conn.cursor() cursor.execute(query) item = cursor.fetchone() t2 = time.time() print t2 t = round(t2-t1) print "from mysql cost %s sec" %t print item mc.set('zhoujinyia',item,60) else : t2 = time.time() t=round(t2-t1) print "from memcache cost %s sec" %t print valueif __name__ =='__main__': mysql_conn = MySQLdb.connect(host='127.0.0.1',user='root',passwd='123456',db='member',port=3306,charset='utf8') get_data(mysql_conn) Note: 上面介绍了一些python连接数据库，大部分的操作没有列出来，具体的请见各官网。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim+zsh tab补全报错]]></title>
    <url>%2F2016%2F11%2F09%2Fvim-zsh%E4%BD%BF%E7%94%A8tab%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[vim+zsh 报错’_arguments:450: _vim_files: function definition file not found’ 今天配置了给测试机器配置了zsh环境,但是使用vim的tab补全命令,无法补全.一直报错.google之,发现解决问题的方法 报错截图: 解决方法:1$ rm ~/.zcompdump PS:原因未知.参考资料: segmentfault]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
</search>
